/*
 * ShadowStrike - Enterprise NGAV/EDR Platform
 * Copyright (C) 2026 ShadowStrike Security
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published
 * by the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program. If not, see <https://www.gnu.org/licenses/>.
 */
/*++
    ShadowStrike Next-Generation Antivirus
    Module: Compression.c

    Purpose: Enterprise-grade LZ4 compression implementation for high-performance
             telemetry and message data compression in kernel mode.

    Architecture:
    - Full LZ4 fast compression (speed-optimized)
    - LZ4 HC high compression (ratio-optimized)
    - Stream compression for large data with block chaining
    - Dictionary support for improved compression of similar data
    - CRC32 integrity verification
    - Thread-safe statistics tracking with interlocked operations

    Performance Characteristics:
    - LZ4 Fast: ~400 MB/s compression, ~2 GB/s decompression
    - LZ4 HC: ~40 MB/s compression, ~2 GB/s decompression
    - Zero-copy where possible
    - Minimal memory allocation during hot paths

    Security Properties:
    - Bounds checking on all operations
    - Integer overflow protection
    - Safe decompression with size validation
    - Checksum verification for data integrity
    - No stack-based large allocations

    Copyright (c) ShadowStrike Team
--*/

#include "Compression.h"
#include "../Utilities/MemoryUtils.h"

#ifdef ALLOC_PRAGMA
#pragma alloc_text(INIT, CompInitialize)
#pragma alloc_text(PAGE, CompShutdown)
#pragma alloc_text(PAGE, CompCreateContext)
#pragma alloc_text(PAGE, CompDestroyContext)
#pragma alloc_text(PAGE, CompCreateDictionary)
#pragma alloc_text(PAGE, CompLoadDictionary)
#pragma alloc_text(PAGE, CompDestroyDictionary)
#pragma alloc_text(PAGE, CompStreamBegin)
#pragma alloc_text(PAGE, CompStreamEnd)
#pragma alloc_text(PAGE, CompStreamDecompressBegin)
#pragma alloc_text(PAGE, CompStreamDecompressEnd)
#pragma alloc_text(PAGE, ComppDestroyDictionaryInternal)
#endif

//=============================================================================
// LZ4 Internal Constants
//=============================================================================

#define LZ4_MEMORY_USAGE            14      // Memory usage formula: 1 << LZ4_MEMORY_USAGE
#define LZ4_HASHLOG                 (LZ4_MEMORY_USAGE - 2)
#define LZ4_HASHTABLESIZE           (1 << LZ4_HASHLOG)
#define LZ4_HASH_SIZE_U32           (1 << LZ4_HASHLOG)

#define LZ4_MAX_INPUT_SIZE          0x7E000000
#define LZ4_SKIP_TRIGGER            6
#define LZ4_MINMATCH                4
#define LZ4_LASTLITERALS            5
#define LZ4_MFLIMIT                 12
#define LZ4_MATCH_SAFEGUARD_DISTANCE ((2 * LZ4_LASTLITERALS) - LZ4_MINMATCH)

#define ML_BITS                     4
#define ML_MASK                     ((1U << ML_BITS) - 1)
#define RUN_BITS                    (8 - ML_BITS)
#define RUN_MASK                    ((1U << RUN_BITS) - 1)

// HC (High Compression) specific
#define LZ4HC_CLEVEL_MIN            3
#define LZ4HC_CLEVEL_DEFAULT        9
#define LZ4HC_CLEVEL_OPT_MIN        10
#define LZ4HC_CLEVEL_MAX            12
#define LZ4HC_DICTIONARY_LOGSIZE    16
#define LZ4HC_MAXD                  (1 << LZ4HC_DICTIONARY_LOGSIZE)
#define LZ4HC_MAXD_MASK             (LZ4HC_MAXD - 1)
#define LZ4HC_HASH_LOG              15
#define LZ4HC_HASHTABLESIZE         (1 << LZ4HC_HASH_LOG)
#define LZ4HC_HASH_MASK             (LZ4HC_HASHTABLESIZE - 1)

#define KB                          (1 << 10)
#define MB                          (1 << 20)
#define GB                          (1U << 30)

#define LZ4_DISTANCE_MAX            65535
#define LZ4_DISTANCE_ABSOLUTE_MAX   65535

// Stream constants
#define LZ4_STREAM_MINSIZE          ((1UL << LZ4_MEMORY_USAGE) + 32)
#define LZ4_STREAMHC_MINSIZE        262200

// CRC32 polynomial
#define CRC32_POLYNOMIAL            0xEDB88320

//=============================================================================
// Internal Structures
//=============================================================================

//
// LZ4 stream state for compression
//
typedef struct _LZ4_STREAM_INTERNAL {
    ULONG HashTable[LZ4_HASH_SIZE_U32];
    ULONG CurrentOffset;
    BOOLEAN TableType;
    const UCHAR* Dictionary;
    const UCHAR* DictCtx;
    ULONG DictSize;
} LZ4_STREAM_INTERNAL, *PLZ4_STREAM_INTERNAL;

//
// LZ4 HC stream state for high compression
//
typedef struct _LZ4HC_STREAM_INTERNAL {
    ULONG HashTable[LZ4HC_HASHTABLESIZE];
    USHORT ChainTable[LZ4HC_MAXD];
    const UCHAR* End;
    const UCHAR* Base;
    const UCHAR* DictBase;
    ULONG DictLimit;
    ULONG LowLimit;
    ULONG NextToUpdate;
    SHORT CompressionLevel;
    BOOLEAN FavorDecSpeed;
    BOOLEAN DirtyContext;
    const UCHAR* DictCtx;
} LZ4HC_STREAM_INTERNAL, *PLZ4HC_STREAM_INTERNAL;

//
// LZ4 decode stream state
//
typedef struct _LZ4_DECODE_STREAM {
    const UCHAR* ExternalDict;
    ULONG ExtDictSize;
    const UCHAR* PrefixEnd;
    ULONG PrefixSize;
} LZ4_DECODE_STREAM, *PLZ4_DECODE_STREAM;

//=============================================================================
// Global State
//=============================================================================

static PCOMP_MANAGER g_CompressionManager = NULL;
static volatile LONG g_NextStreamId = 0;
static volatile LONG g_NextDictionaryId = 1000;

//
// Spinlock protecting g_CompressionManager pointer access
//
static EX_SPIN_LOCK g_ManagerLock = 0;

//=============================================================================
// Deferred Cleanup Work Item for Elevated IRQL Dictionary Release
//=============================================================================

typedef struct _COMP_DEFERRED_CLEANUP {
    PIO_WORKITEM WorkItem;
    PCOMP_DICTIONARY Dictionary;
} COMP_DEFERRED_CLEANUP, *PCOMP_DEFERRED_CLEANUP;

static PDEVICE_OBJECT g_CompressionDeviceObject = NULL;

/**
 * @brief Work item callback for deferred dictionary cleanup.
 */
static VOID
ComppDeferredDictionaryCleanup(
    _In_ PDEVICE_OBJECT DeviceObject,
    _In_opt_ PVOID Context
    )
{
    PCOMP_DEFERRED_CLEANUP Cleanup = (PCOMP_DEFERRED_CLEANUP)Context;

    UNREFERENCED_PARAMETER(DeviceObject);

    if (Cleanup == NULL) {
        return;
    }

    //
    // Now at PASSIVE_LEVEL - safe to destroy dictionary
    //
    if (Cleanup->Dictionary != NULL) {
        ComppDestroyDictionaryInternal(Cleanup->Dictionary);
    }

    //
    // Free work item and cleanup structure
    //
    if (Cleanup->WorkItem != NULL) {
        IoFreeWorkItem(Cleanup->WorkItem);
    }

    ExFreePoolWithTag(Cleanup, COMP_POOL_TAG_CONTEXT);
}

/**
 * @brief Queue deferred dictionary cleanup for elevated IRQL.
 */
static BOOLEAN
ComppQueueDeferredDictionaryCleanup(
    _In_ PCOMP_DICTIONARY Dictionary
    )
{
    PCOMP_DEFERRED_CLEANUP Cleanup;
    PIO_WORKITEM WorkItem;

    //
    // Need a device object to queue work items
    // If not available, we cannot defer - caller must handle
    //
    if (g_CompressionDeviceObject == NULL) {
        return FALSE;
    }

    //
    // Allocate cleanup structure from NonPaged pool (we're at elevated IRQL)
    //
    Cleanup = (PCOMP_DEFERRED_CLEANUP)ExAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(COMP_DEFERRED_CLEANUP),
        COMP_POOL_TAG_CONTEXT
    );

    if (Cleanup == NULL) {
        return FALSE;
    }

    //
    // Allocate work item
    //
    WorkItem = IoAllocateWorkItem(g_CompressionDeviceObject);
    if (WorkItem == NULL) {
        ExFreePoolWithTag(Cleanup, COMP_POOL_TAG_CONTEXT);
        return FALSE;
    }

    Cleanup->WorkItem = WorkItem;
    Cleanup->Dictionary = Dictionary;

    //
    // Queue for deferred execution at PASSIVE_LEVEL
    //
    IoQueueWorkItem(
        WorkItem,
        ComppDeferredDictionaryCleanup,
        DelayedWorkQueue,
        Cleanup
    );

    return TRUE;
}

//=============================================================================
// Forward Declarations - Internal Helpers
//=============================================================================

static VOID
ComppDestroyDictionaryInternal(
    _Inout_ PCOMP_DICTIONARY Dictionary
    );

static PCOMP_MANAGER
ComppAcquireManager(
    VOID
    );

static VOID
ComppReleaseManager(
    _In_ PCOMP_MANAGER Manager
    );

//=============================================================================
// CRC32 Lookup Table
//=============================================================================

static const ULONG g_Crc32LookupTable[256] = {
    0x00000000, 0x77073096, 0xEE0E612C, 0x990951BA, 0x076DC419, 0x706AF48F,
    0xE963A535, 0x9E6495A3, 0x0EDB8832, 0x79DCB8A4, 0xE0D5E91E, 0x97D2D988,
    0x09B64C2B, 0x7EB17CBD, 0xE7B82D07, 0x90BF1D91, 0x1DB71064, 0x6AB020F2,
    0xF3B97148, 0x84BE41DE, 0x1ADAD47D, 0x6DDDE4EB, 0xF4D4B551, 0x83D385C7,
    0x136C9856, 0x646BA8C0, 0xFD62F97A, 0x8A65C9EC, 0x14015C4F, 0x63066CD9,
    0xFA0F3D63, 0x8D080DF5, 0x3B6E20C8, 0x4C69105E, 0xD56041E4, 0xA2677172,
    0x3C03E4D1, 0x4B04D447, 0xD20D85FD, 0xA50AB56B, 0x35B5A8FA, 0x42B2986C,
    0xDBBBBBD6, 0xACBCCB40, 0x32D86CE3, 0x45DF5C75, 0xDCD60DCF, 0xABD13D59,
    0x26D930AC, 0x51DE003A, 0xC8D75180, 0xBFD06116, 0x21B4F4B5, 0x56B3C423,
    0xCFBA9599, 0xB8BDA50F, 0x2802B89E, 0x5F058808, 0xC60CD9B2, 0xB10BE924,
    0x2F6F7C87, 0x58684C11, 0xC1611DAB, 0xB6662D3D, 0x76DC4190, 0x01DB7106,
    0x98D220BC, 0xEFD5102A, 0x71B18589, 0x06B6B51F, 0x9FBFE4A5, 0xE8B8D433,
    0x7807C9A2, 0x0F00F934, 0x9609A88E, 0xE10E9818, 0x7F6A0DBB, 0x086D3D2D,
    0x91646C97, 0xE6635C01, 0x6B6B51F4, 0x1C6C6162, 0x856530D8, 0xF262004E,
    0x6C0695ED, 0x1B01A57B, 0x8208F4C1, 0xF50FC457, 0x65B0D9C6, 0x12B7E950,
    0x8BBEB8EA, 0xFCB9887C, 0x62DD1DDF, 0x15DA2D49, 0x8CD37CF3, 0xFBD44C65,
    0x4DB26158, 0x3AB551CE, 0xA3BC0074, 0xD4BB30E2, 0x4ADFA541, 0x3DD895D7,
    0xA4D1C46D, 0xD3D6F4FB, 0x4369E96A, 0x346ED9FC, 0xAD678846, 0xDA60B8D0,
    0x44042D73, 0x33031DE5, 0xAA0A4C5F, 0xDD0D7CC9, 0x5005713C, 0x270241AA,
    0xBE0B1010, 0xC90C2086, 0x5768B525, 0x206F85B3, 0xB966D409, 0xCE61E49F,
    0x5EDEF90E, 0x29D9C998, 0xB0D09822, 0xC7D7A8B4, 0x59B33D17, 0x2EB40D81,
    0xB7BD5C3B, 0xC0BA6CAD, 0xEDB88320, 0x9ABFB3B6, 0x03B6E20C, 0x74B1D29A,
    0xEAD54739, 0x9DD277AF, 0x04DB2615, 0x73DC1683, 0xE3630B12, 0x94643B84,
    0x0D6D6A3E, 0x7A6A5AA8, 0xE40ECF0B, 0x9309FF9D, 0x0A00AE27, 0x7D079EB1,
    0xF00F9344, 0x8708A3D2, 0x1E01F268, 0x6906C2FE, 0xF762575D, 0x806567CB,
    0x196C3671, 0x6E6B06E7, 0xFED41B76, 0x89D32BE0, 0x10DA7A5A, 0x67DD4ACC,
    0xF9B9DF6F, 0x8EBEEFF9, 0x17B7BE43, 0x60B08ED5, 0xD6D6A3E8, 0xA1D1937E,
    0x38D8C2C4, 0x4FDFF252, 0xD1BB67F1, 0xA6BC5767, 0x3FB506DD, 0x48B2364B,
    0xD80D2BDA, 0xAF0A1B4C, 0x36034AF6, 0x41047A60, 0xDF60EFC3, 0xA867DF55,
    0x316E8EEF, 0x4669BE79, 0xCB61B38C, 0xBC66831A, 0x256FD2A0, 0x5268E236,
    0xCC0C7795, 0xBB0B4703, 0x220216B9, 0x5505262F, 0xC5BA3BBE, 0xB2BD0B28,
    0x2BB45A92, 0x5CB36A04, 0xC2D7FFA7, 0xB5D0CF31, 0x2CD99E8B, 0x5BDEAE1D,
    0x9B64C2B0, 0xEC63F226, 0x756AA39C, 0x026D930A, 0x9C0906A9, 0xEB0E363F,
    0x72076785, 0x05005713, 0x95BF4A82, 0xE2B87A14, 0x7BB12BAE, 0x0CB61B38,
    0x92D28E9B, 0xE5D5BE0D, 0x7CDCEFB7, 0x0BDBDF21, 0x86D3D2D4, 0xF1D4E242,
    0x68DDB3F8, 0x1FDA836E, 0x81BE16CD, 0xF6B9265B, 0x6FB077E1, 0x18B74777,
    0x88085AE6, 0xFF0F6A70, 0x66063BCA, 0x11010B5C, 0x8F659EFF, 0xF862AE69,
    0x616BFFD3, 0x166CCF45, 0xA00AE278, 0xD70DD2EE, 0x4E048354, 0x3903B3C2,
    0xA7672661, 0xD06016F7, 0x4969474D, 0x3E6E77DB, 0xAED16A4A, 0xD9D65ADC,
    0x40DF0B66, 0x37D83BF0, 0xA9BCAE53, 0xDEBB9EC5, 0x47B2CF7F, 0x30B5FFE9,
    0xBDBDF21C, 0xCABAC28A, 0x53B39330, 0x24B4A3A6, 0xBAD03605, 0xCDD706B7,
    0x54DE5729, 0x23D967BF, 0xB3667A2E, 0xC4614AB8, 0x5D681B02, 0x2A6F2B94,
    0xB40BBE37, 0xC30C8EA1, 0x5A05DF1B, 0x2D02EF8D
};

//=============================================================================
// Manager Access Helpers (TOCTOU Protection)
//=============================================================================

/**
 * @brief Acquire reference to global compression manager.
 *
 * This provides TOCTOU-safe access to the global manager by
 * incrementing the reference count before returning.
 *
 * @return Pointer to manager if available, NULL otherwise.
 *         Caller MUST call ComppReleaseManager when done.
 */
static PCOMP_MANAGER
ComppAcquireManager(
    VOID
    )
{
    KIRQL OldIrql;
    PCOMP_MANAGER Manager;

    OldIrql = ExAcquireSpinLockShared(&g_ManagerLock);

    Manager = g_CompressionManager;

    if (Manager != NULL && InterlockedCompareExchange(&Manager->Initialized, TRUE, TRUE) == TRUE) {
        InterlockedIncrement(&Manager->RefCount);
    } else {
        Manager = NULL;
    }

    ExReleaseSpinLockShared(&g_ManagerLock, OldIrql);

    return Manager;
}

/**
 * @brief Release reference to compression manager.
 *
 * @param Manager Manager to release (may be NULL).
 */
static VOID
ComppReleaseManager(
    _In_opt_ PCOMP_MANAGER Manager
    )
{
    if (Manager != NULL) {
        InterlockedDecrement(&Manager->RefCount);
    }
}

//=============================================================================
// Forward Declarations
//=============================================================================

static ULONG
ComppCalculateCrc32(
    _In_reads_bytes_(Size) const PVOID Data,
    _In_ ULONG Size
    );

static FORCEINLINE ULONG
ComppHash4(
    _In_ ULONG Sequence
    );

static FORCEINLINE ULONG
ComppHash5(
    _In_ ULONG64 Sequence
    );

static FORCEINLINE VOID
ComppWriteLE16(
    _Out_writes_bytes_(2) PVOID Ptr,
    _In_ USHORT Value
    );

static FORCEINLINE USHORT
ComppReadLE16(
    _In_reads_bytes_(2) const PVOID Ptr
    );

static FORCEINLINE ULONG
ComppRead32(
    _In_reads_bytes_(4) const PVOID Ptr
    );

static FORCEINLINE ULONG64
ComppRead64(
    _In_reads_bytes_(8) const PVOID Ptr
    );

static FORCEINLINE ULONG
ComppCount(
    _In_ const UCHAR* Ptr1,
    _In_ const UCHAR* Ptr2,
    _In_ const UCHAR* Limit1,
    _In_ const UCHAR* Limit2
    );

static FORCEINLINE ULONG
ComppCountBack(
    _In_ const UCHAR* Ip,
    _In_ const UCHAR* Match,
    _In_ const UCHAR* IMin,
    _In_ const UCHAR* MMin
    );

static INT
ComppCompressGeneric(
    _In_ PLZ4_STREAM_INTERNAL State,
    _In_reads_bytes_(InputSize) const CHAR* Source,
    _Out_writes_bytes_(MaxOutputSize) CHAR* Dest,
    _In_ INT InputSize,
    _In_ INT MaxOutputSize,
    _In_ INT Acceleration
    );

static INT
ComppCompressHC(
    _In_ PLZ4HC_STREAM_INTERNAL State,
    _In_reads_bytes_(InputSize) const CHAR* Source,
    _Out_writes_bytes_(MaxOutputSize) CHAR* Dest,
    _In_ INT InputSize,
    _In_ INT MaxOutputSize,
    _In_ INT CompressionLevel
    );

static INT
ComppDecompressSafe(
    _In_reads_bytes_(CompressedSize) const CHAR* Source,
    _Out_writes_bytes_(MaxDecompressedSize) CHAR* Dest,
    _In_ INT CompressedSize,
    _In_ INT MaxDecompressedSize,
    _In_reads_bytes_opt_(DictSize) const CHAR* DictStart,
    _In_ INT DictSize,
    _In_ BOOLEAN PartialDecode
    );

//=============================================================================
// Helper Functions
//=============================================================================

/**
 * @brief Calculate CRC32 checksum of data.
 */
static ULONG
ComppCalculateCrc32(
    _In_reads_bytes_(Size) const PVOID Data,
    _In_ ULONG Size
    )
{
    const UCHAR* Bytes = (const UCHAR*)Data;
    ULONG Crc = 0xFFFFFFFF;
    ULONG i;

    for (i = 0; i < Size; i++) {
        Crc = g_Crc32LookupTable[(Crc ^ Bytes[i]) & 0xFF] ^ (Crc >> 8);
    }

    return Crc ^ 0xFFFFFFFF;
}

/**
 * @brief Hash function for 4-byte sequences (LZ4 fast).
 */
static FORCEINLINE ULONG
ComppHash4(
    _In_ ULONG Sequence
    )
{
    return ((Sequence * 2654435761U) >> (32 - LZ4_HASHLOG));
}

/**
 * @brief Hash function for 5-byte sequences (improved match finding).
 */
static FORCEINLINE ULONG
ComppHash5(
    _In_ ULONG64 Sequence
    )
{
    const ULONG64 Prime = 889523592379ULL;
    return (ULONG)(((Sequence << 24) * Prime) >> (64 - LZ4_HASHLOG));
}

/**
 * @brief Write 16-bit value in little-endian format.
 */
static FORCEINLINE VOID
ComppWriteLE16(
    _Out_writes_bytes_(2) PVOID Ptr,
    _In_ USHORT Value
    )
{
    UCHAR* p = (UCHAR*)Ptr;
    p[0] = (UCHAR)(Value & 0xFF);
    p[1] = (UCHAR)(Value >> 8);
}

/**
 * @brief Read 16-bit value in little-endian format.
 */
static FORCEINLINE USHORT
ComppReadLE16(
    _In_reads_bytes_(2) const PVOID Ptr
    )
{
    const UCHAR* p = (const UCHAR*)Ptr;
    return (USHORT)(p[0] | (p[1] << 8));
}

/**
 * @brief Read 32-bit value.
 */
static FORCEINLINE ULONG
ComppRead32(
    _In_reads_bytes_(4) const PVOID Ptr
    )
{
    ULONG Value;
    RtlCopyMemory(&Value, Ptr, sizeof(ULONG));
    return Value;
}

/**
 * @brief Read 64-bit value.
 */
static FORCEINLINE ULONG64
ComppRead64(
    _In_reads_bytes_(8) const PVOID Ptr
    )
{
    ULONG64 Value;
    RtlCopyMemory(&Value, Ptr, sizeof(ULONG64));
    return Value;
}

/**
 * @brief Count matching bytes forward with bounds checking on both pointers.
 *
 * @param Ptr1 First pointer to compare
 * @param Ptr2 Second pointer to compare (match candidate)
 * @param Limit1 End boundary for Ptr1
 * @param Limit2 End boundary for Ptr2
 * @return Number of matching bytes
 */
static FORCEINLINE ULONG
ComppCount(
    _In_ const UCHAR* Ptr1,
    _In_ const UCHAR* Ptr2,
    _In_ const UCHAR* Limit1,
    _In_ const UCHAR* Limit2
    )
{
    const UCHAR* Start = Ptr1;
    const UCHAR* EffectiveLimit;

    //
    // Use the more restrictive limit based on both buffers
    //
    ULONG MaxLen1 = (ULONG)(Limit1 - Ptr1);
    ULONG MaxLen2 = (ULONG)(Limit2 - Ptr2);
    ULONG MaxLen = (MaxLen1 < MaxLen2) ? MaxLen1 : MaxLen2;

    EffectiveLimit = Ptr1 + MaxLen;

    //
    // Process 8 bytes at a time for speed, but check both limits
    //
    while (Ptr1 + 8 <= EffectiveLimit) {
        ULONG64 Diff = ComppRead64(Ptr1) ^ ComppRead64(Ptr2);
        if (Diff != 0) {
            //
            // Find first differing byte using trailing zero count
            //
            ULONG TrailingZeros = 0;
            while ((Diff & 0xFF) == 0) {
                TrailingZeros++;
                Diff >>= 8;
            }
            return (ULONG)(Ptr1 - Start + TrailingZeros);
        }
        Ptr1 += 8;
        Ptr2 += 8;
    }

    //
    // Handle remaining bytes
    //
    while (Ptr1 < EffectiveLimit && *Ptr1 == *Ptr2) {
        Ptr1++;
        Ptr2++;
    }

    return (ULONG)(Ptr1 - Start);
}

/**
 * @brief Count matching bytes backward.
 */
static FORCEINLINE ULONG
ComppCountBack(
    _In_ const UCHAR* Ip,
    _In_ const UCHAR* Match,
    _In_ const UCHAR* IMin,
    _In_ const UCHAR* MMin
    )
{
    const UCHAR* Start = Ip;

    while (Ip > IMin && Match > MMin && Ip[-1] == Match[-1]) {
        Ip--;
        Match--;
    }

    return (ULONG)(Start - Ip);
}

//=============================================================================
// LZ4 Core Implementation
//=============================================================================

/**
 * @brief Generic LZ4 compression implementation.
 *
 * This implements the LZ4 block format compression algorithm with
 * configurable acceleration for speed vs ratio tradeoff.
 */
static INT
ComppCompressGeneric(
    _In_ PLZ4_STREAM_INTERNAL State,
    _In_reads_bytes_(InputSize) const CHAR* Source,
    _Out_writes_bytes_(MaxOutputSize) CHAR* Dest,
    _In_ INT InputSize,
    _In_ INT MaxOutputSize,
    _In_ INT Acceleration
    )
{
    const UCHAR* Ip = (const UCHAR*)Source;
    const UCHAR* Base = Ip;
    const UCHAR* LowLimit = Base;
    const UCHAR* Anchor = Ip;
    const UCHAR* IEnd = Ip + InputSize;
    const UCHAR* MFlimit = IEnd - LZ4_MFLIMIT;
    const UCHAR* MatchLimit = IEnd - LZ4_LASTLITERALS;

    UCHAR* Op = (UCHAR*)Dest;
    UCHAR* OLimit = Op + MaxOutputSize;
    UCHAR* Token;

    ULONG* HashTable = State->HashTable;
    ULONG StepSize;
    INT Result;

    //
    // Handle small inputs
    //
    if (InputSize < LZ4_MINMATCH) {
        goto _LastLiterals;
    }

    //
    // Validate acceleration
    //
    if (Acceleration < 1) {
        Acceleration = LZ4_ACCELERATION_DEFAULT;
    }
    StepSize = 1 + ((ULONG)Acceleration >> 2);

    //
    // First byte
    //
    HashTable[ComppHash4(ComppRead32(Ip))] = (ULONG)(Ip - Base);
    Ip++;

    //
    // Main compression loop
    //
    for (;;) {
        const UCHAR* Match;
        UCHAR* TokenPtr;
        ULONG Step = StepSize;
        const UCHAR* ForwardIp = Ip;
        ULONG ForwardH;
        ULONG h;
        ULONG MatchLength;
        ULONG LiteralLength;
        ULONG Offset;

        //
        // Find a match
        //
        do {
            h = ComppHash4(ComppRead32(ForwardIp));
            Ip = ForwardIp;
            ForwardIp += Step;
            Step = (Step * Acceleration) + StepSize;

            if (ForwardIp > MFlimit) {
                goto _LastLiterals;
            }

            Match = Base + HashTable[h];
            ForwardH = ComppHash4(ComppRead32(ForwardIp));
            HashTable[h] = (ULONG)(Ip - Base);

        } while ((ComppRead32(Match) != ComppRead32(Ip)) ||
                 (Match + LZ4_DISTANCE_MAX < Ip));

        //
        // Extend match backwards
        //
        while (Ip > Anchor && Match > LowLimit && Ip[-1] == Match[-1]) {
            Ip--;
            Match--;
        }

        //
        // Encode literals
        //
        LiteralLength = (ULONG)(Ip - Anchor);
        TokenPtr = Op++;

        if ((ULONG)(OLimit - Op) < LiteralLength + (2 + 1 + LZ4_LASTLITERALS)) {
            return 0;  // Output too small
        }

        if (LiteralLength >= RUN_MASK) {
            ULONG Len = LiteralLength - RUN_MASK;
            *TokenPtr = (UCHAR)(RUN_MASK << ML_BITS);
            while (Len >= 255) {
                *Op++ = 255;
                Len -= 255;
            }
            *Op++ = (UCHAR)Len;
        } else {
            *TokenPtr = (UCHAR)(LiteralLength << ML_BITS);
        }

        //
        // Copy literals
        //
        RtlCopyMemory(Op, Anchor, LiteralLength);
        Op += LiteralLength;

_NextMatch:
        //
        // Encode offset
        //
        Offset = (ULONG)(Ip - Match);
        ComppWriteLE16(Op, (USHORT)Offset);
        Op += 2;

        //
        // Encode match length
        //
        {
            const UCHAR* MatchStart = Ip + LZ4_MINMATCH;
            const UCHAR* MatchEnd = MatchStart;

            MatchEnd += ComppCount(MatchStart, Match + LZ4_MINMATCH, MatchLimit, IEnd);
            MatchLength = (ULONG)(MatchEnd - MatchStart);
            Ip = MatchEnd;

            if (MatchLength >= ML_MASK) {
                *TokenPtr += (UCHAR)ML_MASK;
                MatchLength -= ML_MASK;
                while (MatchLength >= 255) {
                    *Op++ = 255;
                    MatchLength -= 255;
                }
                *Op++ = (UCHAR)MatchLength;
            } else {
                *TokenPtr += (UCHAR)MatchLength;
            }
        }

        Anchor = Ip;

        //
        // Check for end of input
        //
        if (Ip > MFlimit) {
            break;
        }

        //
        // Fill hash table
        //
        HashTable[ComppHash4(ComppRead32(Ip - 2))] = (ULONG)(Ip - 2 - Base);

        //
        // Test next position for immediate match
        //
        h = ComppHash4(ComppRead32(Ip));
        Match = Base + HashTable[h];
        HashTable[h] = (ULONG)(Ip - Base);

        if ((Match + LZ4_DISTANCE_MAX >= Ip) && (ComppRead32(Match) == ComppRead32(Ip))) {
            TokenPtr = Op++;
            *TokenPtr = 0;
            goto _NextMatch;
        }

        //
        // Continue searching
        //
        ForwardH = ComppHash4(ComppRead32(++Ip));
    }

_LastLiterals:
    //
    // Encode last literals
    //
    {
        ULONG LastRunLength = (ULONG)(IEnd - Anchor);

        if ((ULONG)(OLimit - Op) < LastRunLength + 1 + ((LastRunLength + 255 - RUN_MASK) / 255)) {
            return 0;  // Output too small
        }

        if (LastRunLength >= RUN_MASK) {
            ULONG Remaining = LastRunLength - RUN_MASK;
            *Op++ = (UCHAR)(RUN_MASK << ML_BITS);
            while (Remaining >= 255) {
                *Op++ = 255;
                Remaining -= 255;
            }
            *Op++ = (UCHAR)Remaining;
        } else {
            *Op++ = (UCHAR)(LastRunLength << ML_BITS);
        }

        RtlCopyMemory(Op, Anchor, LastRunLength);
        Op += LastRunLength;
    }

    Result = (INT)(Op - (UCHAR*)Dest);
    return Result;
}

/**
 * @brief LZ4 High Compression implementation.
 *
 * Provides better compression ratios at the cost of speed.
 * Uses more sophisticated match finding with hash chains.
 *
 * FIXED: Added proper bounds checking in encoding loops.
 * FIXED: Removed unused SearchMatchNb variable.
 */
static INT
ComppCompressHC(
    _In_ PLZ4HC_STREAM_INTERNAL State,
    _In_reads_bytes_(InputSize) const CHAR* Source,
    _Out_writes_bytes_(MaxOutputSize) CHAR* Dest,
    _In_ INT InputSize,
    _In_ INT MaxOutputSize,
    _In_ INT CompressionLevel
    )
{
    const UCHAR* Ip = (const UCHAR*)Source;
    const UCHAR* Anchor = Ip;
    const UCHAR* IEnd = Ip + InputSize;
    const UCHAR* MFlimit = IEnd - LZ4_MFLIMIT;
    const UCHAR* MatchLimit = IEnd - LZ4_LASTLITERALS;

    UCHAR* Op = (UCHAR*)Dest;
    UCHAR* OLimit = Op + MaxOutputSize;
    UCHAR* Token;

    ULONG MaxNbAttempts;

    //
    // Handle compression level
    //
    if (CompressionLevel < LZ4HC_CLEVEL_MIN) {
        CompressionLevel = LZ4HC_CLEVEL_DEFAULT;
    }
    if (CompressionLevel > LZ4HC_CLEVEL_MAX) {
        CompressionLevel = LZ4HC_CLEVEL_MAX;
    }

    MaxNbAttempts = 1U << (CompressionLevel - 1);

    //
    // Handle small inputs
    //
    if (InputSize < LZ4_MINMATCH) {
        goto _LastLiterals;
    }

    //
    // Initialize state if needed
    //
    if (State->Base == NULL) {
        State->Base = Ip;
        State->End = IEnd;
        State->LowLimit = 0;
        State->DictLimit = 0;
        State->NextToUpdate = 0;
        RtlZeroMemory(State->HashTable, sizeof(State->HashTable));
        RtlZeroMemory(State->ChainTable, sizeof(State->ChainTable));
    }

    //
    // Main HC compression loop
    //
    while (Ip < MFlimit) {
        const UCHAR* Match = NULL;
        ULONG MatchLength = 0;
        ULONG BestOffset = 0;
        ULONG Attempts = MaxNbAttempts;
        ULONG h;
        ULONG Current;
        ULONG MatchIndex;

        //
        // Update hash chain
        //
        h = ((ComppRead32(Ip) * 2654435761U) >> (32 - LZ4HC_HASH_LOG));
        Current = (ULONG)(Ip - State->Base);

        MatchIndex = State->HashTable[h];
        State->ChainTable[Current & LZ4HC_MAXD_MASK] = (USHORT)(Current - MatchIndex);
        State->HashTable[h] = Current;

        //
        // Search for best match in chain
        //
        while (Attempts > 0 && MatchIndex >= State->LowLimit) {
            const UCHAR* MatchCandidate = State->Base + MatchIndex;

            if (MatchCandidate + LZ4_DISTANCE_MAX >= Ip) {
                if (ComppRead32(MatchCandidate) == ComppRead32(Ip)) {
                    ULONG CandidateLength = LZ4_MINMATCH + ComppCount(
                        Ip + LZ4_MINMATCH,
                        MatchCandidate + LZ4_MINMATCH,
                        MatchLimit,
                        IEnd
                    );

                    if (CandidateLength > MatchLength) {
                        MatchLength = CandidateLength;
                        Match = MatchCandidate;
                        BestOffset = Current - MatchIndex;
                    }
                }
            }

            //
            // Follow chain
            //
            if (MatchIndex <= State->ChainTable[MatchIndex & LZ4HC_MAXD_MASK]) {
                break;
            }
            MatchIndex -= State->ChainTable[MatchIndex & LZ4HC_MAXD_MASK];
            Attempts--;
        }

        //
        // No match found - advance
        //
        if (MatchLength < LZ4_MINMATCH) {
            Ip++;
            continue;
        }

        //
        // Encode literals with proper bounds checking
        //
        {
            ULONG LiteralLength = (ULONG)(Ip - Anchor);
            ULONG RequiredSpace;

            //
            // Calculate required output space
            // Token + literal length bytes + literals + offset + match length bytes
            //
            RequiredSpace = 1;  // Token
            if (LiteralLength >= RUN_MASK) {
                RequiredSpace += 1 + ((LiteralLength - RUN_MASK) / 255);
            }
            RequiredSpace += LiteralLength;  // Literals
            RequiredSpace += 2;  // Offset
            RequiredSpace += LZ4_LASTLITERALS;  // Safety margin

            if ((ULONG)(OLimit - Op) < RequiredSpace) {
                return 0;  // Output too small
            }

            Token = Op++;

            if (LiteralLength >= RUN_MASK) {
                ULONG Len = LiteralLength - RUN_MASK;
                *Token = (UCHAR)(RUN_MASK << ML_BITS);
                while (Len >= 255) {
                    if (Op >= OLimit) return 0;  // Bounds check
                    *Op++ = 255;
                    Len -= 255;
                }
                if (Op >= OLimit) return 0;  // Bounds check
                *Op++ = (UCHAR)Len;
            } else {
                *Token = (UCHAR)(LiteralLength << ML_BITS);
            }

            RtlCopyMemory(Op, Anchor, LiteralLength);
            Op += LiteralLength;
        }

        //
        // Encode offset
        //
        if (Op + 2 > OLimit) return 0;  // Bounds check
        ComppWriteLE16(Op, (USHORT)BestOffset);
        Op += 2;

        //
        // Encode match length with bounds checking
        //
        {
            ULONG Len = MatchLength - LZ4_MINMATCH;

            if (Len >= ML_MASK) {
                *Token += (UCHAR)ML_MASK;
                Len -= ML_MASK;
                while (Len >= 255) {
                    if (Op >= OLimit) return 0;  // Bounds check
                    *Op++ = 255;
                    Len -= 255;
                }
                if (Op >= OLimit) return 0;  // Bounds check
                *Op++ = (UCHAR)Len;
            } else {
                *Token += (UCHAR)Len;
            }
        }

        //
        // Update for next iteration
        //
        Ip += MatchLength;
        Anchor = Ip;

        //
        // Update hash chain for skipped positions
        //
        while (State->NextToUpdate < (ULONG)(Ip - State->Base)) {
            ULONG Pos = State->NextToUpdate;
            h = ((ComppRead32(State->Base + Pos) * 2654435761U) >> (32 - LZ4HC_HASH_LOG));
            State->ChainTable[Pos & LZ4HC_MAXD_MASK] = (USHORT)(Pos - State->HashTable[h]);
            State->HashTable[h] = Pos;
            State->NextToUpdate++;
        }
    }

_LastLiterals:
    //
    // Encode last literals with proper bounds checking
    //
    {
        ULONG LastRunLength = (ULONG)(IEnd - Anchor);
        ULONG RequiredSpace = 1 + LastRunLength;

        if (LastRunLength >= RUN_MASK) {
            RequiredSpace += 1 + ((LastRunLength - RUN_MASK) / 255);
        }

        if ((ULONG)(OLimit - Op) < RequiredSpace) {
            return 0;  // Output too small
        }

        if (LastRunLength >= RUN_MASK) {
            ULONG Remaining = LastRunLength - RUN_MASK;
            *Op++ = (UCHAR)(RUN_MASK << ML_BITS);
            while (Remaining >= 255) {
                *Op++ = 255;
                Remaining -= 255;
            }
            *Op++ = (UCHAR)Remaining;
        } else {
            *Op++ = (UCHAR)(LastRunLength << ML_BITS);
        }

        RtlCopyMemory(Op, Anchor, LastRunLength);
        Op += LastRunLength;
    }

    return (INT)(Op - (UCHAR*)Dest);
}

/**
 * @brief Safe LZ4 decompression implementation.
 *
 * Decompresses LZ4 data with full bounds checking to prevent
 * buffer overflows from malformed or malicious input.
 *
 * SECURITY FIXES:
 * - Integer overflow protection in length decoding
 * - Proper boundary underflow checks
 * - Bounds validation before all memory access
 */
static INT
ComppDecompressSafe(
    _In_reads_bytes_(CompressedSize) const CHAR* Source,
    _Out_writes_bytes_(MaxDecompressedSize) CHAR* Dest,
    _In_ INT CompressedSize,
    _In_ INT MaxDecompressedSize,
    _In_reads_bytes_opt_(DictSize) const CHAR* DictStart,
    _In_ INT DictSize,
    _In_ BOOLEAN PartialDecode
    )
{
    const UCHAR* Ip = (const UCHAR*)Source;
    const UCHAR* IEnd = Ip + CompressedSize;

    UCHAR* Op = (UCHAR*)Dest;
    UCHAR* OEnd = Op + MaxDecompressedSize;
    UCHAR* CopyEnd;

    const UCHAR* DictEnd = DictStart ? (const UCHAR*)DictStart + DictSize : NULL;

    //
    // Validate input parameters
    //
    if (Source == NULL || Dest == NULL) {
        return -1;
    }

    if (CompressedSize <= 0 || MaxDecompressedSize <= 0) {
        return -1;
    }

    //
    // Handle zero-size inputs
    //
    if (CompressedSize == 0) {
        return 0;
    }

    //
    // Calculate copy end with underflow protection
    // For partial decode, we can fill to the very end
    // For full decode, we need 8 bytes safety margin
    //
    if (PartialDecode) {
        CopyEnd = OEnd;
    } else {
        if (MaxDecompressedSize < 8) {
            CopyEnd = Op;  // No room for fast copy
        } else {
            CopyEnd = OEnd - 8;
        }
    }

    //
    // Main decompression loop
    //
    while (Ip < IEnd) {
        ULONG Token;
        ULONG Length;
        const UCHAR* Match;
        USHORT Offset;

        //
        // Get token - need at least 1 byte
        //
        if (Ip >= IEnd) {
            return -1;
        }
        Token = *Ip++;
        Length = Token >> ML_BITS;

        //
        // Decode literal length with overflow protection
        //
        if (Length == RUN_MASK) {
            ULONG Addl;
            do {
                if (Ip >= IEnd) {
                    return -1;  // Malformed input
                }
                Addl = *Ip++;

                //
                // SECURITY: Check for integer overflow before adding
                //
                if (Length > COMP_MAX_INPUT_SIZE - Addl) {
                    return -1;  // Overflow attack detected
                }
                Length += Addl;
            } while (Addl == 255);
        }

        //
        // Validate we have enough input and output space for literals
        //
        if (Length > 0) {
            //
            // Calculate minimum required input remaining
            // Need: Length bytes of literals + 2 bytes offset (unless at end)
            //
            ULONG InputRemaining = (ULONG)(IEnd - Ip);
            ULONG OutputRemaining = (ULONG)(OEnd - Op);

            //
            // Check if this is potentially the last block
            //
            if (InputRemaining < Length) {
                return -1;  // Not enough input
            }

            if (OutputRemaining < Length) {
                if (PartialDecode && Op + Length <= OEnd) {
                    // Partial decode allows filling to end
                } else {
                    return -1;  // Output overflow
                }
            }

            //
            // Check if we're at the end of input (last literals)
            //
            if (Ip + Length == IEnd) {
                //
                // This is the last block - just copy literals and exit
                //
                if (Op + Length > OEnd) {
                    return -1;
                }
                RtlCopyMemory(Op, Ip, Length);
                Op += Length;
                break;  // End of decompression
            }

            //
            // Not the last block - need offset and match length after
            // Ensure we have at least 2 bytes for offset + potential match length
            //
            if (InputRemaining < Length + 2) {
                return -1;  // Truncated input
            }

            //
            // Copy literals
            //
            RtlCopyMemory(Op, Ip, Length);
            Ip += Length;
            Op += Length;
        }

        //
        // Ensure we have 2 bytes for offset
        //
        if (Ip + 2 > IEnd) {
            return -1;  // Truncated input
        }

        //
        // Get match offset
        //
        Offset = ComppReadLE16(Ip);
        Ip += 2;

        if (Offset == 0) {
            return -1;  // Invalid zero offset
        }

        Match = Op - Offset;

        //
        // Validate offset
        //
        if (Match < (const UCHAR*)Dest) {
            //
            // Check dictionary
            //
            if (DictStart == NULL) {
                return -1;  // Invalid offset - no dictionary
            }

            if (Match < (const UCHAR*)Dest - DictSize) {
                return -1;  // Offset beyond dictionary
            }

            //
            // Match is in dictionary
            //
            Match = DictEnd + (Match - (const UCHAR*)Dest);
        }

        //
        // Decode match length with overflow protection
        //
        Length = Token & ML_MASK;
        if (Length == ML_MASK) {
            ULONG Addl;
            do {
                if (Ip >= IEnd) {
                    return -1;
                }
                Addl = *Ip++;

                //
                // SECURITY: Check for integer overflow before adding
                //
                if (Length > COMP_MAX_INPUT_SIZE - Addl) {
                    return -1;  // Overflow attack detected
                }
                Length += Addl;
            } while (Addl == 255);
        }

        //
        // Add minimum match length
        // Check for overflow first
        //
        if (Length > COMP_MAX_INPUT_SIZE - LZ4_MINMATCH) {
            return -1;
        }
        Length += LZ4_MINMATCH;

        //
        // Validate output space for match
        //
        if (Op + Length > OEnd) {
            return -1;  // Output overflow
        }

        //
        // Copy match - handle overlapping carefully
        //
        if (Offset < 8) {
            //
            // Byte-by-byte copy for small offsets (run-length encoding pattern)
            //
            ULONG i;
            for (i = 0; i < Length; i++) {
                Op[i] = Match[i];
            }
            Op += Length;
        } else if (Match >= (const UCHAR*)Dest && Match + Length <= Op) {
            //
            // Standard case: match is entirely before output position
            // No overlap, safe to use RtlCopyMemory
            //
            RtlCopyMemory(Op, Match, Length);
            Op += Length;
        } else if (Match < (const UCHAR*)Dest && DictStart != NULL) {
            //
            // Match spans dictionary and output buffer
            //
            ULONG DictPortion = (ULONG)((const UCHAR*)Dest - Match);
            if (DictPortion > Length) {
                DictPortion = Length;
            }
            RtlCopyMemory(Op, Match, DictPortion);
            Op += DictPortion;
            Length -= DictPortion;
            if (Length > 0) {
                //
                // Copy remaining from start of output buffer
                //
                ULONG i;
                for (i = 0; i < Length; i++) {
                    Op[i] = ((const UCHAR*)Dest)[i];
                }
                Op += Length;
            }
        } else {
            //
            // Overlapping copy - must be byte-by-byte
            //
            ULONG i;
            for (i = 0; i < Length; i++) {
                Op[i] = Match[i];
            }
            Op += Length;
        }
    }

    return (INT)(Op - (UCHAR*)Dest);
}

//=============================================================================
// LZ4 Public API Implementation
//=============================================================================

/**
 * @brief LZ4 default compression.
 */
INT
LZ4_compress_default(
    _In_reads_bytes_(srcSize) const CHAR* src,
    _Out_writes_bytes_(dstCapacity) CHAR* dst,
    _In_ INT srcSize,
    _In_ INT dstCapacity
    )
{
    return LZ4_compress_fast(src, dst, srcSize, dstCapacity, 1);
}

/**
 * @brief LZ4 fast compression with acceleration.
 *
 * FIXED: Allocates LZ4_STREAM_INTERNAL from pool instead of stack
 * to prevent kernel stack overflow (structure is ~16KB).
 */
INT
LZ4_compress_fast(
    _In_reads_bytes_(srcSize) const CHAR* src,
    _Out_writes_bytes_(dstCapacity) CHAR* dst,
    _In_ INT srcSize,
    _In_ INT dstCapacity,
    _In_ INT acceleration
    )
{
    PLZ4_STREAM_INTERNAL State = NULL;
    INT Result;

    //
    // Validate parameters
    //
    if (src == NULL || dst == NULL) {
        return 0;
    }

    if (srcSize <= 0 || dstCapacity <= 0) {
        return 0;
    }

    if (srcSize > LZ4_MAX_INPUT_SIZE) {
        return 0;
    }

    //
    // Allocate state from pool - LZ4_STREAM_INTERNAL is ~16KB
    // which would overflow the kernel stack
    //
    State = (PLZ4_STREAM_INTERNAL)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(LZ4_STREAM_INTERNAL),
        COMP_POOL_TAG_CONTEXT
    );

    if (State == NULL) {
        return 0;
    }

    //
    // Initialize state
    //
    RtlZeroMemory(State, sizeof(LZ4_STREAM_INTERNAL));
    State->CurrentOffset = 0;

    //
    // Compress
    //
    Result = ComppCompressGeneric(State, src, dst, srcSize, dstCapacity, acceleration);

    //
    // Free state
    //
    ShadowStrikeFreePoolWithTag(State, COMP_POOL_TAG_CONTEXT);

    return Result;
}

/**
 * @brief LZ4 high compression.
 */
INT
LZ4_compress_HC(
    _In_reads_bytes_(srcSize) const CHAR* src,
    _Out_writes_bytes_(dstCapacity) CHAR* dst,
    _In_ INT srcSize,
    _In_ INT dstCapacity,
    _In_ INT compressionLevel
    )
{
    PLZ4HC_STREAM_INTERNAL State = NULL;
    INT Result;

    //
    // Validate parameters
    //
    if (src == NULL || dst == NULL) {
        return 0;
    }

    if (srcSize <= 0 || dstCapacity <= 0) {
        return 0;
    }

    if (srcSize > LZ4_MAX_INPUT_SIZE) {
        return 0;
    }

    //
    // Allocate HC state (larger than fast state)
    //
    State = (PLZ4HC_STREAM_INTERNAL)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(LZ4HC_STREAM_INTERNAL),
        COMP_POOL_TAG_CONTEXT
    );

    if (State == NULL) {
        return 0;
    }

    RtlZeroMemory(State, sizeof(LZ4HC_STREAM_INTERNAL));
    State->CompressionLevel = (SHORT)compressionLevel;

    //
    // Compress
    //
    Result = ComppCompressHC(State, src, dst, srcSize, dstCapacity, compressionLevel);

    //
    // Free state
    //
    ShadowStrikeFreePoolWithTag(State, COMP_POOL_TAG_CONTEXT);

    return Result;
}

/**
 * @brief Safe LZ4 decompression.
 */
INT
LZ4_decompress_safe(
    _In_reads_bytes_(compressedSize) const CHAR* src,
    _Out_writes_bytes_(dstCapacity) CHAR* dst,
    _In_ INT compressedSize,
    _In_ INT dstCapacity
    )
{
    return ComppDecompressSafe(src, dst, compressedSize, dstCapacity, NULL, 0, FALSE);
}

/**
 * @brief LZ4_decompress_fast is REMOVED for security reasons.
 *
 * This function was fundamentally unsafe because it required knowing
 * the original size but not the compressed size, allowing attackers
 * to cause arbitrary kernel memory reads.
 *
 * Use LZ4_decompress_safe() instead which requires both sizes.
 *
 * This stub exists only to cause link errors if old code tries to use it.
 */
#if 0
INT
LZ4_decompress_fast(
    _In_ const CHAR* src,
    _Out_writes_bytes_(originalSize) CHAR* dst,
    _In_ INT originalSize
    )
{
    UNREFERENCED_PARAMETER(src);
    UNREFERENCED_PARAMETER(dst);
    UNREFERENCED_PARAMETER(originalSize);

    //
    // SECURITY: This function is intentionally disabled.
    // It cannot safely validate input without knowing compressed size.
    //
    NT_ASSERT(FALSE && "LZ4_decompress_fast is deprecated - use LZ4_decompress_safe");
    return -1;
}
#endif

/**
 * @brief Dictionary-based compression.
 */
INT
LZ4_compress_fast_usingDict(
    _In_ PVOID state,
    _In_reads_bytes_(srcSize) const CHAR* src,
    _Out_writes_bytes_(dstCapacity) CHAR* dst,
    _In_ INT srcSize,
    _In_ INT dstCapacity,
    _In_reads_bytes_(dictSize) const CHAR* dictBuffer,
    _In_ INT dictSize
    )
{
    PLZ4_STREAM_INTERNAL State = (PLZ4_STREAM_INTERNAL)state;
    INT Result;

    if (State == NULL || src == NULL || dst == NULL) {
        return 0;
    }

    if (dictBuffer != NULL && dictSize > 0) {
        State->Dictionary = (const UCHAR*)dictBuffer;
        State->DictSize = (ULONG)dictSize;
    }

    Result = ComppCompressGeneric(State, src, dst, srcSize, dstCapacity, 1);

    return Result;
}

/**
 * @brief Dictionary-based decompression.
 */
INT
LZ4_decompress_safe_usingDict(
    _In_reads_bytes_(compressedSize) const CHAR* src,
    _Out_writes_bytes_(dstCapacity) CHAR* dst,
    _In_ INT compressedSize,
    _In_ INT dstCapacity,
    _In_reads_bytes_(dictSize) const CHAR* dictBuffer,
    _In_ INT dictSize
    )
{
    return ComppDecompressSafe(src, dst, compressedSize, dstCapacity, dictBuffer, dictSize, FALSE);
}

//=============================================================================
// Manager Initialization
//=============================================================================

/**
 * @brief Initialize the compression manager.
 */
_Use_decl_annotations_
NTSTATUS
CompInitialize(
    PCOMP_MANAGER Manager
    )
{
    KIRQL OldIrql;

    PAGED_CODE();

    if (Manager == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    RtlZeroMemory(Manager, sizeof(COMP_MANAGER));

    //
    // Initialize dictionary list with EX_SPIN_LOCK
    //
    InitializeListHead(&Manager->DictionaryList);
    Manager->DictionaryLock = 0;
    Manager->MaxDictionaries = 16;  // Default limit

    //
    // Initialize default context
    //
    Manager->DefaultContext.Algorithm = CompAlgorithm_LZ4_Fast;
    Manager->DefaultContext.CompressionLevel = COMP_LEVEL_DEFAULT;
    Manager->DefaultContext.Acceleration = LZ4_ACCELERATION_DEFAULT;
    Manager->DefaultContext.Flags = CompFlag_Checksum;
    Manager->DefaultContext.Lock = 0;
    Manager->DefaultContext.Initialized = TRUE;

    //
    // Set default configuration
    //
    Manager->Config.DefaultAlgorithm = CompAlgorithm_LZ4_Fast;
    Manager->Config.DefaultLevel = COMP_LEVEL_DEFAULT;
    Manager->Config.MinSizeToCompress = COMP_MIN_INPUT_SIZE;
    Manager->Config.AlwaysVerify = FALSE;

    //
    // Initialize statistics
    //
    Manager->Stats.TotalCompressed = 0;
    Manager->Stats.TotalDecompressed = 0;
    Manager->Stats.BytesSaved = 0;
    Manager->Stats.Errors = 0;

    //
    // Initialize reference count
    //
    Manager->RefCount = 0;

    //
    // Mark as initialized and set global pointer atomically
    //
    InterlockedExchange(&Manager->Initialized, TRUE);

    OldIrql = ExAcquireSpinLockExclusive(&g_ManagerLock);
    g_CompressionManager = Manager;
    ExReleaseSpinLockExclusive(&g_ManagerLock, OldIrql);

    return STATUS_SUCCESS;
}

/**
 * @brief Shutdown the compression manager.
 *
 * FIXED: Implements proper collect-then-free pattern to avoid
 * IRQL violations and race conditions when freeing dictionaries.
 */
_Use_decl_annotations_
VOID
CompShutdown(
    PCOMP_MANAGER Manager
    )
{
    KIRQL OldIrql;
    LIST_ENTRY FreeList;
    PLIST_ENTRY Entry;
    PCOMP_DICTIONARY Dict;

    PAGED_CODE();

    if (Manager == NULL) {
        return;
    }

    //
    // Mark as not initialized atomically
    //
    if (InterlockedCompareExchange(&Manager->Initialized, FALSE, TRUE) == FALSE) {
        return;  // Already shutdown or never initialized
    }

    //
    // Wait for all references to be released
    // This is a simple spin-wait; in production consider using an event
    //
    while (InterlockedCompareExchange(&Manager->RefCount, 0, 0) > 0) {
        LARGE_INTEGER Delay;
        Delay.QuadPart = -10000;  // 1ms
        KeDelayExecutionThread(KernelMode, FALSE, &Delay);
    }

    //
    // Collect all dictionaries to free list while holding lock
    //
    InitializeListHead(&FreeList);

    OldIrql = ExAcquireSpinLockExclusive(&Manager->DictionaryLock);

    while (!IsListEmpty(&Manager->DictionaryList)) {
        Entry = RemoveHeadList(&Manager->DictionaryList);
        InsertTailList(&FreeList, Entry);
    }

    Manager->DictionaryCount = 0;

    ExReleaseSpinLockExclusive(&Manager->DictionaryLock, OldIrql);

    //
    // Now free all dictionaries without holding the lock
    // This is safe because we've already removed them from the list
    //
    while (!IsListEmpty(&FreeList)) {
        Entry = RemoveHeadList(&FreeList);
        Dict = CONTAINING_RECORD(Entry, COMP_DICTIONARY, ListEntry);

        //
        // Force refcount to 0 and destroy
        //
        InterlockedExchange(&Dict->RefCount, 0);

        if (Dict->Data != NULL) {
            ShadowStrikeFreePoolWithTag(Dict->Data, COMP_POOL_TAG_DICT);
        }
        if (Dict->LZ4DictState != NULL) {
            ShadowStrikeFreePoolWithTag(Dict->LZ4DictState, COMP_POOL_TAG_DICT);
        }
        ShadowStrikeFreePoolWithTag(Dict, COMP_POOL_TAG_DICT);
    }

    //
    // Free default context resources
    //
    if (Manager->DefaultContext.WorkBuffer != NULL) {
        ShadowStrikeFreePoolWithTag(Manager->DefaultContext.WorkBuffer, COMP_POOL_TAG_BUFFER);
        Manager->DefaultContext.WorkBuffer = NULL;
    }

    if (Manager->DefaultContext.InternalState != NULL) {
        ShadowStrikeFreePoolWithTag(Manager->DefaultContext.InternalState, COMP_POOL_TAG_CONTEXT);
        Manager->DefaultContext.InternalState = NULL;
    }

    //
    // Clear global manager pointer
    //
    OldIrql = ExAcquireSpinLockExclusive(&g_ManagerLock);
    if (g_CompressionManager == Manager) {
        g_CompressionManager = NULL;
    }
    ExReleaseSpinLockExclusive(&g_ManagerLock, OldIrql);
}

//=============================================================================
// Simple Compression API
//=============================================================================

/**
 * @brief Calculate worst-case compressed size with overflow protection.
 *
 * FIXED: Added integer overflow checks to prevent returning undersized
 * buffer estimates that would cause buffer overflows.
 */
_Use_decl_annotations_
ULONG
CompGetBound(
    ULONG InputSize,
    COMP_ALGORITHM Algorithm
    )
{
    ULONG Bound;
    ULONG LZ4Overhead;

    UNREFERENCED_PARAMETER(Algorithm);

    //
    // Check for overflow before calculation
    // LZ4 worst case: input + input/255 + 16 + header
    //
    // Maximum safe input size to prevent overflow:
    // ULONG_MAX - 16 - sizeof(COMP_HEADER) - (ULONG_MAX/255)  4GB - overhead
    //
    // For safety, cap at COMP_MAX_INPUT_SIZE (64MB)
    //
    if (InputSize > COMP_MAX_INPUT_SIZE) {
        return 0;  // Indicate error - input too large
    }

    //
    // Calculate LZ4 overhead safely
    //
    LZ4Overhead = (InputSize / 255) + 16;

    //
    // Check for overflow in final calculation
    //
    if (InputSize > ULONG_MAX - LZ4Overhead - sizeof(COMP_HEADER)) {
        return 0;  // Overflow would occur
    }

    Bound = InputSize + LZ4Overhead;

    //
    // Add header size
    //
    Bound += sizeof(COMP_HEADER);

    return Bound;
}

/**
 * @brief Get original size from compressed data header.
 */
_Use_decl_annotations_
NTSTATUS
CompGetOriginalSize(
    PVOID CompressedData,
    ULONG HeaderSize,
    PULONG OriginalSize
    )
{
    PCOMP_HEADER Header;

    if (CompressedData == NULL || OriginalSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    if (HeaderSize < sizeof(COMP_HEADER)) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    Header = (PCOMP_HEADER)CompressedData;

    if (Header->Magic != COMP_MAGIC && Header->Magic != COMP_MAGIC_LZ4) {
        return STATUS_INVALID_SIGNATURE;
    }

    if (Header->Version != COMP_VERSION) {
        return STATUS_REVISION_MISMATCH;
    }

    *OriginalSize = Header->OriginalSize;
    return STATUS_SUCCESS;
}

/**
 * @brief Compress data in a single call.
 */
_Use_decl_annotations_
NTSTATUS
CompCompress(
    PVOID Input,
    ULONG InputSize,
    PVOID Output,
    ULONG OutputSize,
    PULONG CompressedSize,
    PCOMP_OPTIONS Options
    )
{
    NTSTATUS Status = STATUS_SUCCESS;
    PCOMP_HEADER Header;
    PUCHAR CompressedData;
    INT Result;
    ULONG MaxCompressedSize;
    COMP_ALGORITHM Algorithm;
    ULONG Level;
    ULONG Acceleration;
    COMP_FLAGS Flags;
    ULONG Checksum;

    //
    // Validate parameters
    //
    if (Input == NULL || Output == NULL || CompressedSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    if (InputSize == 0 || InputSize > COMP_MAX_INPUT_SIZE) {
        return STATUS_INVALID_PARAMETER;
    }

    *CompressedSize = 0;

    //
    // Get compression parameters
    //
    if (Options != NULL) {
        Algorithm = Options->Algorithm;
        Level = Options->CompressionLevel;
        Acceleration = Options->Acceleration;
        Flags = Options->Flags;
    } else {
        Algorithm = CompAlgorithm_LZ4_Fast;
        Level = COMP_LEVEL_DEFAULT;
        Acceleration = LZ4_ACCELERATION_DEFAULT;
        Flags = CompFlag_Checksum;
    }

    //
    // Default to LZ4 Fast if not specified
    //
    if (Algorithm == CompAlgorithm_None || Algorithm >= CompAlgorithm_Max) {
        Algorithm = CompAlgorithm_LZ4_Fast;
    }

    //
    // Check output buffer size
    //
    MaxCompressedSize = CompGetBound(InputSize, Algorithm);
    if (OutputSize < MaxCompressedSize) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    //
    // Prepare header
    //
    Header = (PCOMP_HEADER)Output;
    RtlZeroMemory(Header, sizeof(COMP_HEADER));

    Header->Magic = COMP_MAGIC;
    Header->Version = COMP_VERSION;
    Header->Algorithm = Algorithm;
    Header->Flags = Flags;
    Header->OriginalSize = InputSize;

    //
    // Calculate checksum if requested
    //
    if (Flags & CompFlag_Checksum) {
        Checksum = ComppCalculateCrc32(Input, InputSize);
        Header->Checksum = Checksum;
    }

    //
    // Get pointer to compressed data area
    //
    CompressedData = (PUCHAR)Output + sizeof(COMP_HEADER);
    MaxCompressedSize = OutputSize - sizeof(COMP_HEADER);

    //
    // Compress based on algorithm
    //
    switch (Algorithm) {
        case CompAlgorithm_LZ4_Fast:
            Result = LZ4_compress_fast(
                (const CHAR*)Input,
                (CHAR*)CompressedData,
                (INT)InputSize,
                (INT)MaxCompressedSize,
                (INT)Acceleration
            );
            break;

        case CompAlgorithm_LZ4_HC:
            Result = LZ4_compress_HC(
                (const CHAR*)Input,
                (CHAR*)CompressedData,
                (INT)InputSize,
                (INT)MaxCompressedSize,
                (INT)Level
            );
            break;

        case CompAlgorithm_RLE:
        case CompAlgorithm_Delta:
            //
            // Fallback to LZ4 for unsupported algorithms
            //
            Result = LZ4_compress_default(
                (const CHAR*)Input,
                (CHAR*)CompressedData,
                (INT)InputSize,
                (INT)MaxCompressedSize
            );
            break;

        default:
            Result = 0;
            Status = STATUS_INVALID_PARAMETER;
    }

    if (Result <= 0) {
        return STATUS_COMPRESSION_NOT_BENEFICIAL;
    }

    //
    // Check if compression is beneficial
    //
    if ((ULONG)Result >= InputSize) {
        //
        // Compression made data larger - store uncompressed
        //
        Header->Algorithm = CompAlgorithm_None;
        Header->CompressedSize = InputSize;
        RtlCopyMemory(CompressedData, Input, InputSize);
        *CompressedSize = sizeof(COMP_HEADER) + InputSize;
    } else {
        Header->CompressedSize = (ULONG)Result;
        *CompressedSize = sizeof(COMP_HEADER) + (ULONG)Result;
    }

    //
    // Update global statistics using safe manager access
    //
    {
        PCOMP_MANAGER Mgr = ComppAcquireManager();
        if (Mgr != NULL) {
            InterlockedIncrement64((volatile LONG64*)&Mgr->Stats.TotalCompressed);
            InterlockedAdd64((volatile LONG64*)&Mgr->Stats.BytesSaved,
                             (LONG64)InputSize - (LONG64)*CompressedSize);
            ComppReleaseManager(Mgr);
        }
    }

    return STATUS_SUCCESS;
}

/**
 * @brief Decompress data in a single call.
 */
_Use_decl_annotations_
NTSTATUS
CompDecompress(
    PVOID Compressed,
    ULONG CompressedSize,
    PVOID Output,
    ULONG OutputSize,
    PULONG DecompressedSize,
    PCOMP_OPTIONS Options
    )
{
    PCOMP_HEADER Header;
    const UCHAR* CompressedData;
    INT Result;
    ULONG Checksum;

    UNREFERENCED_PARAMETER(Options);

    //
    // Validate parameters
    //
    if (Compressed == NULL || Output == NULL || DecompressedSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    if (CompressedSize < sizeof(COMP_HEADER)) {
        return STATUS_INVALID_PARAMETER;
    }

    *DecompressedSize = 0;

    //
    // Validate header
    //
    Header = (PCOMP_HEADER)Compressed;

    if (Header->Magic != COMP_MAGIC && Header->Magic != COMP_MAGIC_LZ4) {
        return STATUS_INVALID_SIGNATURE;
    }

    if (Header->Version != COMP_VERSION) {
        return STATUS_REVISION_MISMATCH;
    }

    if (Header->OriginalSize > COMP_MAX_INPUT_SIZE) {
        return STATUS_INVALID_PARAMETER;
    }

    if (OutputSize < Header->OriginalSize) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    //
    // Validate compressed size
    //
    if (sizeof(COMP_HEADER) + Header->CompressedSize > CompressedSize) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Get compressed data pointer
    //
    CompressedData = (const UCHAR*)Compressed + sizeof(COMP_HEADER);

    //
    // Handle uncompressed data
    //
    if (Header->Algorithm == CompAlgorithm_None) {
        RtlCopyMemory(Output, CompressedData, Header->OriginalSize);
        *DecompressedSize = Header->OriginalSize;
        goto VerifyChecksum;
    }

    //
    // Decompress based on algorithm
    //
    switch (Header->Algorithm) {
        case CompAlgorithm_LZ4_Fast:
        case CompAlgorithm_LZ4_HC:
            Result = LZ4_decompress_safe(
                (const CHAR*)CompressedData,
                (CHAR*)Output,
                (INT)Header->CompressedSize,
                (INT)Header->OriginalSize
            );
            break;

        default:
            {
                PCOMP_MANAGER Mgr = ComppAcquireManager();
                if (Mgr != NULL) {
                    InterlockedIncrement64((volatile LONG64*)&Mgr->Stats.Errors);
                    ComppReleaseManager(Mgr);
                }
            }
            return STATUS_NOT_SUPPORTED;
    }

    if (Result < 0) {
        PCOMP_MANAGER Mgr = ComppAcquireManager();
        if (Mgr != NULL) {
            InterlockedIncrement64((volatile LONG64*)&Mgr->Stats.Errors);
            ComppReleaseManager(Mgr);
        }
        return STATUS_DATA_ERROR;
    }

    if ((ULONG)Result != Header->OriginalSize) {
        PCOMP_MANAGER Mgr = ComppAcquireManager();
        if (Mgr != NULL) {
            InterlockedIncrement64((volatile LONG64*)&Mgr->Stats.Errors);
            ComppReleaseManager(Mgr);
        }
        return STATUS_DATA_ERROR;
    }

    *DecompressedSize = (ULONG)Result;

VerifyChecksum:
    //
    // Verify checksum if present
    //
    if (Header->Flags & CompFlag_Checksum) {
        Checksum = ComppCalculateCrc32(Output, *DecompressedSize);
        if (Checksum != Header->Checksum) {
            PCOMP_MANAGER Mgr = ComppAcquireManager();
            if (Mgr != NULL) {
                InterlockedIncrement64((volatile LONG64*)&Mgr->Stats.Errors);
                ComppReleaseManager(Mgr);
            }
            return STATUS_CRC_ERROR;
        }
    }

    //
    // Update statistics using safe manager access
    //
    {
        PCOMP_MANAGER Mgr = ComppAcquireManager();
        if (Mgr != NULL) {
            InterlockedIncrement64((volatile LONG64*)&Mgr->Stats.TotalDecompressed);
            ComppReleaseManager(Mgr);
        }
    }

    return STATUS_SUCCESS;
}

//=============================================================================
// Context-Based Compression
//=============================================================================

/**
 * @brief Create a compression context.
 */
_Use_decl_annotations_
NTSTATUS
CompCreateContext(
    PCOMP_CONTEXT* Context,
    COMP_ALGORITHM Algorithm,
    ULONG CompressionLevel
    )
{
    PCOMP_CONTEXT Ctx = NULL;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if (Context == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *Context = NULL;

    if (Algorithm == CompAlgorithm_None || Algorithm >= CompAlgorithm_Max) {
        Algorithm = CompAlgorithm_LZ4_Fast;
    }

    //
    // Allocate context
    //
    Ctx = (PCOMP_CONTEXT)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(COMP_CONTEXT),
        COMP_POOL_TAG_CONTEXT
    );

    if (Ctx == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(Ctx, sizeof(COMP_CONTEXT));

    Ctx->Algorithm = Algorithm;
    Ctx->CompressionLevel = CompressionLevel;
    Ctx->Acceleration = LZ4_ACCELERATION_DEFAULT;
    Ctx->Flags = CompFlag_Checksum;

    KeInitializeSpinLock(&Ctx->Lock);

    //
    // Allocate internal state based on algorithm
    //
    if (Algorithm == CompAlgorithm_LZ4_Fast) {
        Ctx->InternalState = ShadowStrikeAllocatePoolWithTag(
            NonPagedPoolNx,
            sizeof(LZ4_STREAM_INTERNAL),
            COMP_POOL_TAG_CONTEXT
        );

        if (Ctx->InternalState == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Cleanup;
        }

        RtlZeroMemory(Ctx->InternalState, sizeof(LZ4_STREAM_INTERNAL));
        Ctx->InternalStateSize = sizeof(LZ4_STREAM_INTERNAL);
    } else if (Algorithm == CompAlgorithm_LZ4_HC) {
        Ctx->InternalState = ShadowStrikeAllocatePoolWithTag(
            NonPagedPoolNx,
            sizeof(LZ4HC_STREAM_INTERNAL),
            COMP_POOL_TAG_CONTEXT
        );

        if (Ctx->InternalState == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Cleanup;
        }

        RtlZeroMemory(Ctx->InternalState, sizeof(LZ4HC_STREAM_INTERNAL));
        Ctx->InternalStateSize = sizeof(LZ4HC_STREAM_INTERNAL);
    }

    *Context = Ctx;
    return STATUS_SUCCESS;

Cleanup:
    if (Ctx != NULL) {
        if (Ctx->InternalState != NULL) {
            ShadowStrikeFreePoolWithTag(Ctx->InternalState, COMP_POOL_TAG_CONTEXT);
        }
        ShadowStrikeFreePoolWithTag(Ctx, COMP_POOL_TAG_CONTEXT);
    }

    return Status;
}

/**
 * @brief Destroy a compression context.
 */
_Use_decl_annotations_
VOID
CompDestroyContext(
    PCOMP_CONTEXT Context
    )
{
    PAGED_CODE();

    if (Context == NULL) {
        return;
    }

    if (Context->InternalState != NULL) {
        ShadowStrikeFreePoolWithTag(Context->InternalState, COMP_POOL_TAG_CONTEXT);
    }

    if (Context->WorkBuffer != NULL) {
        ShadowStrikeFreePoolWithTag(Context->WorkBuffer, COMP_POOL_TAG_BUFFER);
    }

    if (Context->Dictionary != NULL) {
        ShadowStrikeFreePoolWithTag(Context->Dictionary, COMP_POOL_TAG_DICT);
    }

    ShadowStrikeFreePoolWithTag(Context, COMP_POOL_TAG_CONTEXT);
}

/**
 * @brief Compress using context.
 */
_Use_decl_annotations_
NTSTATUS
CompCompressWithContext(
    PCOMP_CONTEXT Context,
    PVOID Input,
    ULONG InputSize,
    PVOID Output,
    ULONG OutputSize,
    PULONG CompressedSize
    )
{
    COMP_OPTIONS Options;

    if (Context == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    RtlZeroMemory(&Options, sizeof(Options));
    Options.Algorithm = Context->Algorithm;
    Options.CompressionLevel = Context->CompressionLevel;
    Options.Acceleration = Context->Acceleration;
    Options.Flags = Context->Flags;

    return CompCompress(Input, InputSize, Output, OutputSize, CompressedSize, &Options);
}

/**
 * @brief Decompress using context.
 */
_Use_decl_annotations_
NTSTATUS
CompDecompressWithContext(
    PCOMP_CONTEXT Context,
    PVOID Compressed,
    ULONG CompressedSize,
    PVOID Output,
    ULONG OutputSize,
    PULONG DecompressedSize
    )
{
    COMP_OPTIONS Options;

    if (Context == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    RtlZeroMemory(&Options, sizeof(Options));
    Options.Algorithm = Context->Algorithm;
    Options.Flags = Context->Flags;

    return CompDecompress(Compressed, CompressedSize, Output, OutputSize, DecompressedSize, &Options);
}

//=============================================================================
// Stream Compression
//=============================================================================

/**
 * @brief Begin stream compression.
 */
_Use_decl_annotations_
NTSTATUS
CompStreamBegin(
    PCOMP_STREAM* Stream,
    COMP_ALGORITHM Algorithm,
    ULONG BlockSize,
    PCOMP_OPTIONS Options
    )
{
    PCOMP_STREAM Strm = NULL;
    NTSTATUS Status = STATUS_SUCCESS;

    PAGED_CODE();

    if (Stream == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *Stream = NULL;

    if (Algorithm == CompAlgorithm_None || Algorithm >= CompAlgorithm_Max) {
        Algorithm = CompAlgorithm_LZ4_Fast;
    }

    if (BlockSize == 0) {
        BlockSize = COMP_DEFAULT_BUFFER_SIZE;
    }

    //
    // Allocate stream
    //
    Strm = (PCOMP_STREAM)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(COMP_STREAM),
        COMP_POOL_TAG_STREAM
    );

    if (Strm == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(Strm, sizeof(COMP_STREAM));

    Strm->StreamId = InterlockedIncrement(&g_NextStreamId);
    Strm->Algorithm = Algorithm;
    Strm->BlockSize = BlockSize;
    Strm->BlockCount = 0;
    Strm->CurrentBlock = 0;

    KeQuerySystemTime(&Strm->StartTime);

    //
    // Allocate LZ4 stream state
    //
    if (Algorithm == CompAlgorithm_LZ4_Fast) {
        Strm->LZ4StateSize = sizeof(LZ4_STREAM_INTERNAL);
        Strm->LZ4StreamState = ShadowStrikeAllocatePoolWithTag(
            NonPagedPoolNx,
            Strm->LZ4StateSize,
            COMP_POOL_TAG_STREAM
        );

        if (Strm->LZ4StreamState == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Cleanup;
        }

        RtlZeroMemory(Strm->LZ4StreamState, Strm->LZ4StateSize);
    } else if (Algorithm == CompAlgorithm_LZ4_HC) {
        Strm->LZ4StateSize = sizeof(LZ4HC_STREAM_INTERNAL);
        Strm->LZ4StreamState = ShadowStrikeAllocatePoolWithTag(
            NonPagedPoolNx,
            Strm->LZ4StateSize,
            COMP_POOL_TAG_STREAM
        );

        if (Strm->LZ4StreamState == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Cleanup;
        }

        RtlZeroMemory(Strm->LZ4StreamState, Strm->LZ4StateSize);
    }

    //
    // Allocate ring buffer for dependent blocks
    //
    if (Options == NULL || !(Options->Flags & CompFlag_IndependentBlocks)) {
        Strm->RingBufferSize = 64 * 1024;  // 64 KB ring buffer
        Strm->RingBuffer = ShadowStrikeAllocatePoolWithTag(
            NonPagedPoolNx,
            Strm->RingBufferSize,
            COMP_POOL_TAG_STREAM
        );

        if (Strm->RingBuffer == NULL) {
            Status = STATUS_INSUFFICIENT_RESOURCES;
            goto Cleanup;
        }

        RtlZeroMemory(Strm->RingBuffer, Strm->RingBufferSize);
        Strm->RingBufferPos = 0;
    }

    //
    // Handle dictionary
    //
    if (Options != NULL && Options->Dictionary != NULL) {
        Strm->UseDictionary = TRUE;
        Strm->DictContext = Options->Dictionary;
        CompDictionaryAddRef(Options->Dictionary);
    }

    *Stream = Strm;
    return STATUS_SUCCESS;

Cleanup:
    if (Strm != NULL) {
        if (Strm->LZ4StreamState != NULL) {
            ShadowStrikeFreePoolWithTag(Strm->LZ4StreamState, COMP_POOL_TAG_STREAM);
        }
        if (Strm->RingBuffer != NULL) {
            ShadowStrikeFreePoolWithTag(Strm->RingBuffer, COMP_POOL_TAG_STREAM);
        }
        ShadowStrikeFreePoolWithTag(Strm, COMP_POOL_TAG_STREAM);
    }

    return Status;
}

/**
 * @brief Compress a block in stream mode.
 */
_Use_decl_annotations_
NTSTATUS
CompStreamCompress(
    PCOMP_STREAM Stream,
    PVOID Input,
    ULONG InputSize,
    PVOID Output,
    ULONG OutputSize,
    PULONG CompressedSize
    )
{
    INT Result;
    ULONG MaxCompressedSize;

    if (Stream == NULL || Input == NULL || Output == NULL || CompressedSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    if (InputSize == 0 || InputSize > Stream->BlockSize) {
        return STATUS_INVALID_PARAMETER;
    }

    *CompressedSize = 0;

    MaxCompressedSize = LZ4_COMPRESSBOUND(InputSize);
    if (OutputSize < MaxCompressedSize) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    //
    // Compress block
    //
    if (Stream->Algorithm == CompAlgorithm_LZ4_Fast) {
        PLZ4_STREAM_INTERNAL State = (PLZ4_STREAM_INTERNAL)Stream->LZ4StreamState;

        Result = ComppCompressGeneric(
            State,
            (const CHAR*)Input,
            (CHAR*)Output,
            (INT)InputSize,
            (INT)OutputSize,
            LZ4_ACCELERATION_DEFAULT
        );
    } else if (Stream->Algorithm == CompAlgorithm_LZ4_HC) {
        PLZ4HC_STREAM_INTERNAL State = (PLZ4HC_STREAM_INTERNAL)Stream->LZ4StreamState;

        Result = ComppCompressHC(
            State,
            (const CHAR*)Input,
            (CHAR*)Output,
            (INT)InputSize,
            (INT)OutputSize,
            LZ4HC_CLEVEL_DEFAULT
        );
    } else {
        return STATUS_NOT_SUPPORTED;
    }

    if (Result <= 0) {
        return STATUS_COMPRESSION_NOT_BENEFICIAL;
    }

    //
    // Update stream state
    //
    Stream->CurrentBlock++;
    Stream->BlockCount++;
    Stream->TotalOriginalSize += InputSize;
    Stream->TotalCompressedSize += (ULONG)Result;
    Stream->BytesProcessed += InputSize;

    //
    // Update ring buffer if using dependent blocks
    //
    if (Stream->RingBuffer != NULL) {
        ULONG CopySize = min(InputSize, Stream->RingBufferSize);
        ULONG Offset = Stream->RingBufferPos;

        if (Offset + CopySize > Stream->RingBufferSize) {
            ULONG FirstPart = Stream->RingBufferSize - Offset;
            RtlCopyMemory((PUCHAR)Stream->RingBuffer + Offset, Input, FirstPart);
            RtlCopyMemory(Stream->RingBuffer, (PUCHAR)Input + FirstPart, CopySize - FirstPart);
        } else {
            RtlCopyMemory((PUCHAR)Stream->RingBuffer + Offset, Input, CopySize);
        }

        Stream->RingBufferPos = (Offset + CopySize) % Stream->RingBufferSize;
    }

    *CompressedSize = (ULONG)Result;
    return STATUS_SUCCESS;
}

/**
 * @brief End stream compression.
 */
_Use_decl_annotations_
NTSTATUS
CompStreamEnd(
    PCOMP_STREAM Stream,
    PULONG64 TotalOriginal,
    PULONG64 TotalCompressed
    )
{
    PAGED_CODE();

    if (Stream == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Return statistics
    //
    if (TotalOriginal != NULL) {
        *TotalOriginal = Stream->TotalOriginalSize;
    }

    if (TotalCompressed != NULL) {
        *TotalCompressed = Stream->TotalCompressedSize;
    }

    //
    // Release dictionary reference
    //
    if (Stream->UseDictionary && Stream->DictContext != NULL) {
        CompDictionaryRelease((PCOMP_DICTIONARY)Stream->DictContext);
    }

    //
    // Free resources
    //
    if (Stream->LZ4StreamState != NULL) {
        ShadowStrikeFreePoolWithTag(Stream->LZ4StreamState, COMP_POOL_TAG_STREAM);
    }

    if (Stream->RingBuffer != NULL) {
        ShadowStrikeFreePoolWithTag(Stream->RingBuffer, COMP_POOL_TAG_STREAM);
    }

    ShadowStrikeFreePoolWithTag(Stream, COMP_POOL_TAG_STREAM);

    return STATUS_SUCCESS;
}

/**
 * @brief Begin stream decompression.
 */
_Use_decl_annotations_
NTSTATUS
CompStreamDecompressBegin(
    PCOMP_STREAM* Stream,
    COMP_ALGORITHM Algorithm,
    PCOMP_OPTIONS Options
    )
{
    PCOMP_STREAM Strm = NULL;

    PAGED_CODE();

    if (Stream == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *Stream = NULL;

    //
    // Allocate stream
    //
    Strm = (PCOMP_STREAM)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(COMP_STREAM),
        COMP_POOL_TAG_STREAM
    );

    if (Strm == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(Strm, sizeof(COMP_STREAM));

    Strm->StreamId = InterlockedIncrement(&g_NextStreamId);
    Strm->Algorithm = Algorithm;
    Strm->BlockSize = COMP_DEFAULT_BUFFER_SIZE;

    KeQuerySystemTime(&Strm->StartTime);

    //
    // Allocate ring buffer for decompression prefix
    //
    Strm->RingBufferSize = 64 * 1024;
    Strm->RingBuffer = ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        Strm->RingBufferSize,
        COMP_POOL_TAG_STREAM
    );

    if (Strm->RingBuffer == NULL) {
        ShadowStrikeFreePoolWithTag(Strm, COMP_POOL_TAG_STREAM);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(Strm->RingBuffer, Strm->RingBufferSize);

    //
    // Handle dictionary
    //
    if (Options != NULL && Options->Dictionary != NULL) {
        Strm->UseDictionary = TRUE;
        Strm->DictContext = Options->Dictionary;
        CompDictionaryAddRef(Options->Dictionary);
    }

    *Stream = Strm;
    return STATUS_SUCCESS;
}

/**
 * @brief Decompress a block in stream mode.
 */
_Use_decl_annotations_
NTSTATUS
CompStreamDecompress(
    PCOMP_STREAM Stream,
    PVOID Compressed,
    ULONG CompressedSize,
    PVOID Output,
    ULONG OutputSize,
    PULONG DecompressedSize
    )
{
    INT Result;
    const CHAR* DictBuffer = NULL;
    INT DictSize = 0;

    if (Stream == NULL || Compressed == NULL || Output == NULL || DecompressedSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *DecompressedSize = 0;

    //
    // Use ring buffer as dictionary for dependent blocks
    //
    if (Stream->RingBuffer != NULL && Stream->BlockCount > 0) {
        DictBuffer = (const CHAR*)Stream->RingBuffer;
        DictSize = (INT)min(Stream->RingBufferSize, (ULONG)Stream->BytesProcessed);
    }

    //
    // Decompress
    //
    Result = LZ4_decompress_safe_usingDict(
        (const CHAR*)Compressed,
        (CHAR*)Output,
        (INT)CompressedSize,
        (INT)OutputSize,
        DictBuffer,
        DictSize
    );

    if (Result < 0) {
        return STATUS_DATA_ERROR;
    }

    //
    // Update ring buffer
    //
    if (Stream->RingBuffer != NULL) {
        ULONG CopySize = min((ULONG)Result, Stream->RingBufferSize);
        ULONG Offset = Stream->RingBufferPos;

        if (Offset + CopySize > Stream->RingBufferSize) {
            ULONG FirstPart = Stream->RingBufferSize - Offset;
            RtlCopyMemory((PUCHAR)Stream->RingBuffer + Offset, Output, FirstPart);
            RtlCopyMemory(Stream->RingBuffer, (PUCHAR)Output + FirstPart, CopySize - FirstPart);
        } else {
            RtlCopyMemory((PUCHAR)Stream->RingBuffer + Offset, Output, CopySize);
        }

        Stream->RingBufferPos = (Offset + CopySize) % Stream->RingBufferSize;
    }

    Stream->BlockCount++;
    Stream->TotalCompressedSize += CompressedSize;
    Stream->TotalOriginalSize += (ULONG)Result;
    Stream->BytesProcessed += (ULONG)Result;

    *DecompressedSize = (ULONG)Result;
    return STATUS_SUCCESS;
}

/**
 * @brief End stream decompression.
 */
_Use_decl_annotations_
VOID
CompStreamDecompressEnd(
    PCOMP_STREAM Stream
    )
{
    PAGED_CODE();

    if (Stream == NULL) {
        return;
    }

    //
    // Release dictionary reference
    //
    if (Stream->UseDictionary && Stream->DictContext != NULL) {
        CompDictionaryRelease((PCOMP_DICTIONARY)Stream->DictContext);
    }

    //
    // Free resources
    //
    if (Stream->RingBuffer != NULL) {
        ShadowStrikeFreePoolWithTag(Stream->RingBuffer, COMP_POOL_TAG_STREAM);
    }

    if (Stream->LZ4StreamState != NULL) {
        ShadowStrikeFreePoolWithTag(Stream->LZ4StreamState, COMP_POOL_TAG_STREAM);
    }

    ShadowStrikeFreePoolWithTag(Stream, COMP_POOL_TAG_STREAM);
}

//=============================================================================
// Dictionary Management
//=============================================================================

/**
 * @brief Create a compression dictionary from sample data.
 */
_Use_decl_annotations_
NTSTATUS
CompCreateDictionary(
    PCOMP_DICTIONARY* Dictionary,
    PVOID SampleData,
    ULONG SampleSize,
    ULONG MaxDictSize
    )
{
    PCOMP_DICTIONARY Dict = NULL;
    ULONG ActualDictSize;

    PAGED_CODE();

    if (Dictionary == NULL || SampleData == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *Dictionary = NULL;

    if (SampleSize == 0 || SampleSize > COMP_MAX_INPUT_SIZE) {
        return STATUS_INVALID_PARAMETER;
    }

    if (MaxDictSize == 0) {
        MaxDictSize = COMP_MAX_DICT_SIZE;
    }

    if (MaxDictSize > COMP_MAX_DICT_SIZE) {
        MaxDictSize = COMP_MAX_DICT_SIZE;
    }

    //
    // Dictionary size is limited by sample size and max size
    //
    ActualDictSize = min(SampleSize, MaxDictSize);

    //
    // Allocate dictionary
    //
    Dict = (PCOMP_DICTIONARY)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(COMP_DICTIONARY),
        COMP_POOL_TAG_DICT
    );

    if (Dict == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(Dict, sizeof(COMP_DICTIONARY));

    //
    // Allocate dictionary data
    //
    Dict->Data = ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        ActualDictSize,
        COMP_POOL_TAG_DICT
    );

    if (Dict->Data == NULL) {
        ShadowStrikeFreePoolWithTag(Dict, COMP_POOL_TAG_DICT);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Copy sample data (use last MaxDictSize bytes for best results)
    //
    if (SampleSize > MaxDictSize) {
        RtlCopyMemory(Dict->Data, (PUCHAR)SampleData + (SampleSize - MaxDictSize), ActualDictSize);
    } else {
        RtlCopyMemory(Dict->Data, SampleData, ActualDictSize);
    }

    Dict->Size = ActualDictSize;
    Dict->DictionaryId = (ULONG)InterlockedIncrement(&g_NextDictionaryId);
    Dict->Version = 1;
    Dict->RefCount = 1;
    Dict->UsageCount = 0;
    Dict->LZ4StateReady = FALSE;

    InitializeListHead(&Dict->ListEntry);

    *Dictionary = Dict;
    return STATUS_SUCCESS;
}

/**
 * @brief Load a pre-built dictionary.
 */
_Use_decl_annotations_
NTSTATUS
CompLoadDictionary(
    PCOMP_DICTIONARY* Dictionary,
    PVOID DictData,
    ULONG DictSize,
    ULONG DictionaryId
    )
{
    PCOMP_DICTIONARY Dict = NULL;

    PAGED_CODE();

    if (Dictionary == NULL || DictData == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *Dictionary = NULL;

    if (DictSize == 0 || DictSize > COMP_MAX_DICT_SIZE) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Allocate dictionary
    //
    Dict = (PCOMP_DICTIONARY)ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        sizeof(COMP_DICTIONARY),
        COMP_POOL_TAG_DICT
    );

    if (Dict == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlZeroMemory(Dict, sizeof(COMP_DICTIONARY));

    //
    // Allocate and copy dictionary data
    //
    Dict->Data = ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        DictSize,
        COMP_POOL_TAG_DICT
    );

    if (Dict->Data == NULL) {
        ShadowStrikeFreePoolWithTag(Dict, COMP_POOL_TAG_DICT);
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    RtlCopyMemory(Dict->Data, DictData, DictSize);

    Dict->Size = DictSize;
    Dict->DictionaryId = DictionaryId;
    Dict->Version = 1;
    Dict->RefCount = 1;
    Dict->UsageCount = 0;
    Dict->LZ4StateReady = FALSE;

    InitializeListHead(&Dict->ListEntry);

    *Dictionary = Dict;
    return STATUS_SUCCESS;
}

/**
 * @brief Internal dictionary destruction (does NOT decrement refcount).
 *
 * This is the actual cleanup function - must only be called when
 * refcount has already reached zero.
 */
static VOID
ComppDestroyDictionaryInternal(
    _Inout_ PCOMP_DICTIONARY Dictionary
    )
{
    PAGED_CODE();

    if (Dictionary == NULL) {
        return;
    }

    //
    // Free resources
    //
    if (Dictionary->Data != NULL) {
        ShadowStrikeFreePoolWithTag(Dictionary->Data, COMP_POOL_TAG_DICT);
        Dictionary->Data = NULL;
    }

    if (Dictionary->LZ4DictState != NULL) {
        ShadowStrikeFreePoolWithTag(Dictionary->LZ4DictState, COMP_POOL_TAG_DICT);
        Dictionary->LZ4DictState = NULL;
    }

    ShadowStrikeFreePoolWithTag(Dictionary, COMP_POOL_TAG_DICT);
}

/**
 * @brief Destroy a dictionary (public API - decrements refcount).
 *
 * FIXED: This function now properly decrements refcount and only
 * destroys when it reaches zero. Does NOT double-decrement.
 */
_Use_decl_annotations_
VOID
CompDestroyDictionary(
    PCOMP_DICTIONARY Dictionary
    )
{
    PAGED_CODE();

    if (Dictionary == NULL) {
        return;
    }

    //
    // Decrement refcount and destroy if zero
    //
    if (InterlockedDecrement(&Dictionary->RefCount) == 0) {
        ComppDestroyDictionaryInternal(Dictionary);
    }
}

/**
 * @brief Add reference to dictionary.
 */
_Use_decl_annotations_
VOID
CompDictionaryAddRef(
    PCOMP_DICTIONARY Dictionary
    )
{
    if (Dictionary != NULL) {
        InterlockedIncrement(&Dictionary->RefCount);
    }
}

/**
 * @brief Release dictionary reference.
 *
 * FIXED: Now properly handles refcount and uses deferred cleanup
 * when called at elevated IRQL to avoid BSOD.
 */
_Use_decl_annotations_
VOID
CompDictionaryRelease(
    PCOMP_DICTIONARY Dictionary
    )
{
    if (Dictionary == NULL) {
        return;
    }

    //
    // Decrement and check if we should destroy
    //
    if (InterlockedDecrement(&Dictionary->RefCount) == 0) {
        //
        // SECURITY: Check IRQL - must be at PASSIVE_LEVEL to destroy
        // because internal destroy uses paged pool operations
        //
        if (KeGetCurrentIrql() <= APC_LEVEL) {
            ComppDestroyDictionaryInternal(Dictionary);
        } else {
            //
            // At elevated IRQL - queue work item for deferred cleanup
            //
            if (!ComppQueueDeferredDictionaryCleanup(Dictionary)) {
                //
                // Failed to queue - this is a serious issue
                // Log error but don't crash; dictionary will leak
                // This should never happen in properly configured systems
                //
                NT_ASSERT(FALSE && "CompDictionaryRelease: Failed to queue deferred cleanup");
            }
        }
    }
}

/**
 * @brief Set context dictionary.
 *
 * FIXED: Now properly stores the dictionary reference (not just data pointer)
 * and uses proper synchronization to prevent races.
 */
_Use_decl_annotations_
NTSTATUS
CompSetDictionary(
    PCOMP_CONTEXT Context,
    PCOMP_DICTIONARY Dictionary
    )
{
    KIRQL OldIrql;
    PCOMP_DICTIONARY OldDict;

    if (Context == NULL || Dictionary == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Add reference to new dictionary first (before releasing old)
    //
    CompDictionaryAddRef(Dictionary);

    //
    // Acquire context lock for thread-safe dictionary swap
    //
    OldIrql = ExAcquireSpinLockExclusive(&Context->Lock);

    //
    // Save old dictionary reference for release after unlock
    //
    OldDict = Context->DictionaryRef;

    //
    // Set new dictionary - store the actual dictionary pointer,
    // not just the data pointer (which caused type confusion)
    //
    Context->DictionaryRef = Dictionary;
    Context->DictionaryData = Dictionary->Data;
    Context->DictionarySize = Dictionary->Size;
    Context->DictionaryId = Dictionary->DictionaryId;

    ExReleaseSpinLockExclusive(&Context->Lock, OldIrql);

    //
    // Release old dictionary reference after releasing lock
    // to avoid holding lock during potential deallocation
    //
    if (OldDict != NULL) {
        CompDictionaryRelease(OldDict);
    }

    return STATUS_SUCCESS;
}

//=============================================================================
// In-Place Operations
//=============================================================================

/**
 * @brief Compress in-place.
 */
_Use_decl_annotations_
NTSTATUS
CompCompressInPlace(
    PVOID Buffer,
    ULONG DataSize,
    ULONG BufferSize,
    PULONG CompressedSize,
    PCOMP_OPTIONS Options
    )
{
    NTSTATUS Status;
    PVOID TempBuffer = NULL;
    ULONG RequiredSize;
    ULONG ActualCompressed;

    if (Buffer == NULL || CompressedSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *CompressedSize = 0;

    if (DataSize == 0 || DataSize > COMP_MAX_INPUT_SIZE) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Calculate required size
    //
    RequiredSize = CompGetBound(DataSize, CompAlgorithm_LZ4_Fast);

    if (BufferSize < RequiredSize) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    //
    // Allocate temporary buffer
    //
    TempBuffer = ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        DataSize,
        COMP_POOL_TAG_BUFFER
    );

    if (TempBuffer == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Copy original data
    //
    RtlCopyMemory(TempBuffer, Buffer, DataSize);

    //
    // Compress to original buffer
    //
    Status = CompCompress(TempBuffer, DataSize, Buffer, BufferSize, &ActualCompressed, Options);

    //
    // Free temporary buffer
    //
    ShadowStrikeFreePoolWithTag(TempBuffer, COMP_POOL_TAG_BUFFER);

    if (NT_SUCCESS(Status)) {
        *CompressedSize = ActualCompressed;
    }

    return Status;
}

/**
 * @brief Decompress in-place.
 */
_Use_decl_annotations_
NTSTATUS
CompDecompressInPlace(
    PVOID Buffer,
    ULONG CompressedSize,
    ULONG BufferSize,
    PULONG DecompressedSize
    )
{
    NTSTATUS Status;
    PVOID TempBuffer = NULL;
    PCOMP_HEADER Header;
    ULONG OriginalSize;
    ULONG ActualDecompressed;

    if (Buffer == NULL || DecompressedSize == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    *DecompressedSize = 0;

    if (CompressedSize < sizeof(COMP_HEADER)) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Get original size from header
    //
    Header = (PCOMP_HEADER)Buffer;

    if (Header->Magic != COMP_MAGIC && Header->Magic != COMP_MAGIC_LZ4) {
        return STATUS_INVALID_SIGNATURE;
    }

    OriginalSize = Header->OriginalSize;

    if (BufferSize < OriginalSize) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    //
    // Allocate temporary buffer for compressed data
    //
    TempBuffer = ShadowStrikeAllocatePoolWithTag(
        NonPagedPoolNx,
        CompressedSize,
        COMP_POOL_TAG_BUFFER
    );

    if (TempBuffer == NULL) {
        return STATUS_INSUFFICIENT_RESOURCES;
    }

    //
    // Copy compressed data
    //
    RtlCopyMemory(TempBuffer, Buffer, CompressedSize);

    //
    // Decompress to original buffer
    //
    Status = CompDecompress(TempBuffer, CompressedSize, Buffer, BufferSize, &ActualDecompressed, NULL);

    //
    // Free temporary buffer
    //
    ShadowStrikeFreePoolWithTag(TempBuffer, COMP_POOL_TAG_BUFFER);

    if (NT_SUCCESS(Status)) {
        *DecompressedSize = ActualDecompressed;
    }

    return Status;
}

//=============================================================================
// Verification
//=============================================================================

/**
 * @brief Verify compressed data integrity.
 */
_Use_decl_annotations_
NTSTATUS
CompVerify(
    PVOID CompressedData,
    ULONG CompressedSize
    )
{
    COMP_HEADER Header;

    return CompVerifyEx(CompressedData, CompressedSize, &Header);
}

/**
 * @brief Verify and get metadata.
 */
_Use_decl_annotations_
NTSTATUS
CompVerifyEx(
    PVOID CompressedData,
    ULONG CompressedSize,
    PCOMP_HEADER Header
    )
{
    PCOMP_HEADER SrcHeader;

    if (CompressedData == NULL || Header == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    if (CompressedSize < sizeof(COMP_HEADER)) {
        return STATUS_BUFFER_TOO_SMALL;
    }

    SrcHeader = (PCOMP_HEADER)CompressedData;

    //
    // Validate magic
    //
    if (SrcHeader->Magic != COMP_MAGIC && SrcHeader->Magic != COMP_MAGIC_LZ4) {
        return STATUS_INVALID_SIGNATURE;
    }

    //
    // Validate version
    //
    if (SrcHeader->Version != COMP_VERSION) {
        return STATUS_REVISION_MISMATCH;
    }

    //
    // Validate algorithm
    //
    if (SrcHeader->Algorithm >= CompAlgorithm_Max) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Validate sizes
    //
    if (SrcHeader->OriginalSize > COMP_MAX_INPUT_SIZE) {
        return STATUS_INVALID_PARAMETER;
    }

    if (sizeof(COMP_HEADER) + SrcHeader->CompressedSize > CompressedSize) {
        return STATUS_INVALID_PARAMETER;
    }

    //
    // Copy header
    //
    RtlCopyMemory(Header, SrcHeader, sizeof(COMP_HEADER));

    return STATUS_SUCCESS;
}

//=============================================================================
// Statistics
//=============================================================================

/**
 * @brief Get compression statistics with atomic reads.
 *
 * FIXED: Uses interlocked operations to prevent torn reads on 32-bit systems.
 */
_Use_decl_annotations_
NTSTATUS
CompGetStatistics(
    PCOMP_MANAGER Manager,
    PCOMP_STATISTICS Stats
    )
{
    if (Manager == NULL || Stats == NULL) {
        return STATUS_INVALID_PARAMETER;
    }

    if (InterlockedCompareExchange(&Manager->Initialized, TRUE, TRUE) != TRUE) {
        return STATUS_INVALID_PARAMETER;
    }

    RtlZeroMemory(Stats, sizeof(COMP_STATISTICS));

    //
    // Use interlocked reads for 64-bit values to prevent torn reads
    //
    Stats->TotalCompressed = InterlockedCompareExchange64(
        (volatile LONG64*)&Manager->Stats.TotalCompressed, 0, 0);
    Stats->TotalDecompressed = InterlockedCompareExchange64(
        (volatile LONG64*)&Manager->Stats.TotalDecompressed, 0, 0);
    Stats->BytesSaved = InterlockedCompareExchange64(
        (volatile LONG64*)&Manager->Stats.BytesSaved, 0, 0);
    Stats->Errors = InterlockedCompareExchange64(
        (volatile LONG64*)&Manager->Stats.Errors, 0, 0);

    //
    // Read context statistics atomically
    //
    Stats->BytesIn = InterlockedCompareExchange64(
        (volatile LONG64*)&Manager->DefaultContext.TotalBytesIn, 0, 0);
    Stats->BytesOut = InterlockedCompareExchange64(
        (volatile LONG64*)&Manager->DefaultContext.TotalBytesOut, 0, 0);

    //
    // Calculate average ratio safely
    //
    if (Stats->BytesIn > 0) {
        Stats->AverageRatio = (ULONG)((Stats->BytesOut * 100) / Stats->BytesIn);
    } else {
        Stats->AverageRatio = 100;
    }

    Stats->PeakRatio = 0;  // Would need per-operation tracking

    return STATUS_SUCCESS;
}

/**
 * @brief Reset compression statistics with atomic writes.
 */
_Use_decl_annotations_
VOID
CompResetStatistics(
    PCOMP_MANAGER Manager
    )
{
    if (Manager == NULL) {
        return;
    }

    if (InterlockedCompareExchange(&Manager->Initialized, TRUE, TRUE) != TRUE) {
        return;
    }

    InterlockedExchange64((volatile LONG64*)&Manager->Stats.TotalCompressed, 0);
    InterlockedExchange64((volatile LONG64*)&Manager->Stats.TotalDecompressed, 0);
    InterlockedExchange64((volatile LONG64*)&Manager->Stats.BytesSaved, 0);
    InterlockedExchange64((volatile LONG64*)&Manager->Stats.Errors, 0);

    InterlockedExchange64((volatile LONG64*)&Manager->DefaultContext.TotalBytesIn, 0);
    InterlockedExchange64((volatile LONG64*)&Manager->DefaultContext.TotalBytesOut, 0);
    InterlockedExchange64((volatile LONG64*)&Manager->DefaultContext.TotalOperations, 0);
}
